{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werlang/emolearn-ml-model/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qwpi09Jo6O2S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence, plot_model, to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import TimeDistributed, GRU, LSTM, Dropout, Conv1D, Conv2D, Conv3D, ConvLSTM2D, BatchNormalization, MaxPooling1D, MaxPooling2D, MaxPooling3D, GlobalAveragePooling2D, Flatten, Dense, Input, Add, Activation, AveragePooling3D, AveragePooling2D, ZeroPadding3D, Bidirectional, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, cv2\n",
        "import datetime\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from numba import cuda\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "import functools\n",
        "\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# sm = SMOTE(sampling_strategy=0.6666)\n",
        "# X, y = sm.fit_resample(X, y)\n",
        "\n",
        "\n",
        "drive_save_path = 'drive/My Drive/1NOSYNC/DT/checkpoint'\n",
        "ident_name = 'final'\n",
        "dir_name = '2022-8-8-17-18-19-final'\n",
        "batch_size = 64\n",
        "time_frames = 20\n",
        "interval = 2\n",
        "stride = 1\n",
        "fold_step = 1\n",
        "n_folds = 5\n",
        "\n",
        "epoch = 62\n",
        "\n",
        "\n",
        "def restart():\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "\n",
        "\n",
        "def start_colab():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    !pip install Keras-Applications\n",
        "    # !pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "    !pip install keras-tcn\n",
        "\n",
        "\n",
        "def extract_data():\n",
        "    !mkdir p2m\n",
        "    !mkdir p2m/features\n",
        "\n",
        "    # aligned faces extracted from openface\n",
        "    print(\"COPYING ALIGNED FACES...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/p2m_faces.zip\" -d p2m/features\n",
        "    print(\"COPYING OPENFACE FEATURES...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/p2m_openface.zip\" -d p2m/features\n",
        "    print(\"COPYING LABELS...\")\n",
        "    !cp -r \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/labels.csv\" p2m\n",
        "\n",
        "    print(\"P2M DONE\")\n",
        "\n",
        "    !mkdir daisee\n",
        "    !mkdir daisee/features\n",
        "\n",
        "    print(\"COPYING TRAIN SET...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/daisee_aligned/Train.zip\" -d daisee/features \n",
        "    print(\"COPYING VALIDATION SET...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/daisee_aligned/Validation.zip\" -d daisee/features \n",
        "    print(\"COPYING TEST SET...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/daisee_aligned/Test.zip\" -d daisee/features \n",
        "    print(\"COPYING OPENFACE FEATURES...\")\n",
        "    !unzip -n -q \"drive/My Drive/Doutorado/Implementação/daisee_openface.zip\" -d daisee/of_features\n",
        "    print(\"COPYING LABELS...\")\n",
        "    !cp -r \"drive/My Drive/Doutorado/Implementação/labels\" daisee\n",
        "\n",
        "    print(\"DAISEE DONE\")\n",
        "\n",
        "\n",
        "def create_folds_p2m(em):\n",
        "    # [\"ENGAGEMENT\", \"CONFUSION\", \"FRUSTRATION\", \"BOREDOM\"]\n",
        "    emotionList = [\"engagement\", \"confusion\", \"frustraton\", \"boredom\"]\n",
        "    emotion = emotionList.index(em)\n",
        "    print(\"Emotion: {}\".format(emotionList[emotion]))\n",
        "\n",
        "    num_classes = 2\n",
        "    label_window = time_frames\n",
        "    print(\"CREATING FOLDS...\")\n",
        "    subs = {}\n",
        "\n",
        "    csv = pd.read_csv('p2m/labels.csv')\n",
        "    Y = np.array(csv.iloc[:, 3 + emotion ])\n",
        "    subjects = np.array(csv['SUBJECT'])\n",
        "    clips = np.array(csv['CLIP'])\n",
        "    source_frames = np.array(csv['SOURCE_FRAMES'])\n",
        "\n",
        "    Y = to_categorical(Y, num_classes)    \n",
        "\n",
        "    for i in range(len(subjects)):\n",
        "        if not subjects[i] in subs:\n",
        "            subs[subjects[i]] = [0 for x in range(num_classes)]\n",
        "        subs[subjects[i]] = np.add(subs[subjects[i]], Y[i])\n",
        "\n",
        "    # total = np.sum(Y, axis=0)\n",
        "    # print(total, total / len(Y))\n",
        "    # print(subs)\n",
        "\n",
        "    folds = []\n",
        "    fold_names = []\n",
        "    for i in subs:\n",
        "        if len(folds) < n_folds + 1:\n",
        "            folds.append(subs[i])\n",
        "            fold_names.append([i])\n",
        "        else:\n",
        "            summed = np.sum(folds, axis=1)\n",
        "            index = list(summed).index(min(summed))\n",
        "            folds[index] = np.add(folds[index], subs[i])\n",
        "            fold_names[index].append(i)\n",
        "\n",
        "    # print(folds)\n",
        "    # print(fold_names)\n",
        "    # print(np.sum(folds, axis=1))\n",
        "\n",
        "    # print(\"GETTING FOLDS DATA...\")\n",
        "    # build frames array\n",
        "    videos, labels, opface, xlabel = [], [], [], []\n",
        "    for i in range(len(fold_names)):\n",
        "        videos.append([])\n",
        "        opface.append([])\n",
        "        labels.append([])\n",
        "        xlabel.append([])\n",
        "\n",
        "    fps = 30\n",
        "    skip = int(round(interval * fps / time_frames, 0))\n",
        "\n",
        "    for Yi in range(len(Y)):\n",
        "        print(\"\\rCLIP {}/{}\".format(Yi, len(Y)), end=\"\")\n",
        "        clip = clips[Yi]\n",
        "        start_frame = source_frames[Yi].split(\"-\")[0]\n",
        "        subject = subjects[Yi]\n",
        "\n",
        "        for f in range(n_folds + 1):\n",
        "            if int(subject) in fold_names[f]:\n",
        "                files, filesof = [], []\n",
        "                \n",
        "                of_path = \"p2m/features/{:02}.csv\".format(subject)\n",
        "\n",
        "                for i in range(60):\n",
        "                    image_path = \"p2m/features/faces/{:02}.{:03}.{:02}.jpg\".format(subject, clip, i)\n",
        "                    \n",
        "                    if os.path.isfile(image_path) and os.path.isfile(of_path):\n",
        "                        files.append(image_path)\n",
        "                        filesof.append(\"{}|{}\".format(of_path, int(start_frame) + i))\n",
        "\n",
        "                # append only the parts relative to the video section\n",
        "                last = (len(files) - time_frames*skip) // skip\n",
        "                rg = range(0, last + 1, np.max([1, int(stride * time_frames)]))\n",
        "                for i in rg:\n",
        "                    temp, tpof = [], []\n",
        "                    for j in range(i*skip, (i+time_frames)*skip, skip):\n",
        "                        temp.append(files[j])\n",
        "                        tpof.append(filesof[j])\n",
        "                    videos[f].append(temp)\n",
        "                    opface[f].append(tpof)\n",
        "                    labels[f].append(Y[Yi])\n",
        "\n",
        "                    # get previous clip labels from same subject\n",
        "                    xl = []\n",
        "                    for l in range(Yi - 1, 0, -1):\n",
        "                        sub2 = subjects[l]\n",
        "                        if subject == sub2:\n",
        "                            xl.append(Y[l])\n",
        "                        if len(xl) == label_window:\n",
        "                            break\n",
        "                        \n",
        "                    xl = [(xl[0] if len(xl) > 0 else np.array([0., 1.])) for x in range(label_window - len(xl))] + xl\n",
        "                    xlabel[f].append(xl)\n",
        "\n",
        "\n",
        "    print(\"\\nDONE\")\n",
        "    return videos, opface, xlabel, labels\n",
        "\n",
        "\n",
        "def create_folds_daisee(em):\n",
        "    # [\"Boredom\", \"Engagement\", \"Confusion\", \"Frustration\"]\n",
        "    emotionList = [\"boredom\", \"engagement\", \"confusion\", \"frustraton\"]\n",
        "    emotion = emotionList.index(em)\n",
        "    print(\"Emotion: {}\".format(emotionList[emotion]))\n",
        "\n",
        "    num_classes = 2\n",
        "    label_window = time_frames\n",
        "    print(\"CREATING FOLDS...\")\n",
        "    subs = {}\n",
        "\n",
        "    Y = []\n",
        "    clips = []\n",
        "    # just concatenate all splits\n",
        "    for split in [\"Train\", \"Validation\"]:\n",
        "        csv_path = \"daisee/labels/{}Labels.csv\".format(split)\n",
        "        csv = pd.read_csv(csv_path)\n",
        "        C = np.array(csv['ClipID'])\n",
        "        Yt = np.array(csv.iloc[:,1:])\n",
        "        if len(Y) == 0:\n",
        "            clips = C\n",
        "            Y = Yt\n",
        "        else:\n",
        "            Y = np.concatenate((Y, Yt), axis=0)\n",
        "            clips = np.concatenate((clips, C), axis=0)\n",
        "\n",
        "    Y = to_categorical(np.array(Y[:,emotion]) // (4 // num_classes), num_classes)  \n",
        "\n",
        "    for i in range(len(clips)):\n",
        "        file_name = clips[i].split(\".\")[0]\n",
        "        subject = int(file_name[:6])\n",
        "        if not subject in subs:\n",
        "            subs[subject] = [0 for x in range(num_classes)]\n",
        "        subs[subject] = np.add(subs[subject], Y[i])\n",
        "\n",
        "    # total = np.sum(Y, axis=0)\n",
        "    # print(total, total / len(Y))\n",
        "    # print(subs)\n",
        "\n",
        "    folds = []\n",
        "    fold_names = []\n",
        "    for i in subs:\n",
        "        if len(folds) < n_folds:\n",
        "            folds.append(subs[i])\n",
        "            fold_names.append([i])\n",
        "        else:\n",
        "            summed = np.sum(folds, axis=1)\n",
        "            index = list(summed).index(min(summed))\n",
        "            folds[index] = np.add(folds[index], subs[i])\n",
        "            fold_names[index].append(i)\n",
        "\n",
        "    # print(folds)\n",
        "    # print(fold_names)\n",
        "    # print(np.sum(folds, axis=1))\n",
        "\n",
        "    # print(\"GETTING FOLDS DATA...\")\n",
        "    # build frames array\n",
        "    videos, labels, opface, xlabel = [], [], [], []\n",
        "    for i in range(len(fold_names)):\n",
        "        videos.append([])\n",
        "        opface.append([])\n",
        "        labels.append([])\n",
        "        xlabel.append([])\n",
        "\n",
        "    fps = 15\n",
        "    skip = int(round(interval * fps / time_frames, 0))\n",
        "\n",
        "    split_start = []\n",
        "    csv_path = \"daisee/labels/TrainLabels.csv\"\n",
        "    csv = pd.read_csv(csv_path)\n",
        "    split_start.append(len(csv))\n",
        "    csv_path = \"daisee/labels/ValidationLabels.csv\"\n",
        "    csv = pd.read_csv(csv_path)\n",
        "    split_start.append(split_start[0] + len(csv))\n",
        "\n",
        "    for Yi in range(len(clips)):\n",
        "        print(\"\\rCLIP {}/{}\".format(Yi, len(clips)), end=\"\")\n",
        "        file_name = clips[Yi].split(\".\")[0]\n",
        "        subject = file_name[:6]\n",
        "\n",
        "        for f in range(n_folds):\n",
        "            if int(subject) in fold_names[f]:\n",
        "                # print(\"{}/{}\".format(split, subject))\n",
        "                split = 'Train' if Yi < split_start[0] else 'Validation'\n",
        "                # get aligned faces file names into files array\n",
        "                dir_path = \"daisee/features/{}/{}/{}_aligned\".format(split, subject, file_name)\n",
        "                of_path = \"daisee/of_features/{}/{}/{}.csv\".format(split, subject, file_name)\n",
        "                files, filesof = [], []\n",
        "                \n",
        "                # there are only 150 files in each folder\n",
        "                for i in range(1,350):\n",
        "                    image_path = \"{}/frame_det_00_000{:03d}.jpg\".format(dir_path, i)\n",
        "                    if os.path.isfile(image_path) and os.path.isfile(of_path):\n",
        "                        files.append(image_path)\n",
        "                        filesof.append(\"{}|{}\".format(of_path, i-1))\n",
        "\n",
        "                # append only the parts relative to the video section\n",
        "                last = (len(files) - time_frames*skip) // skip\n",
        "                rg = range(0, last + 1, np.max([1, int(stride * time_frames)]))\n",
        "                for i in rg:\n",
        "                    temp, tpof = [], []\n",
        "                    for j in range(i*skip, (i+time_frames)*skip, skip):\n",
        "                        temp.append(files[j])\n",
        "                        tpof.append(filesof[j])\n",
        "                    videos[f].append(temp)\n",
        "                    opface[f].append(tpof)\n",
        "                    labels[f].append(Y[Yi])\n",
        "\n",
        "                    # get previous clip labels from same subject\n",
        "                    xl = []\n",
        "                    for l in range(Yi - 1, 0, -1):\n",
        "                        sub2 = clips[l].split(\".\")[0][:6]\n",
        "                        if subject == sub2:\n",
        "                            xl.append(Y[l])\n",
        "                        if len(xl) == label_window:\n",
        "                            break\n",
        "                        \n",
        "                    xl = [(xl[0] if len(xl) > 0 else np.array([0., 1.])) for x in range(label_window - len(xl))] + xl\n",
        "                    xlabel[f].append(xl)\n",
        "\n",
        "\n",
        "    # get test fold\n",
        "    print(\"\\nBUILDING TEST DATA\")\n",
        "    csv_path = \"daisee/labels/TestLabels.csv\"\n",
        "    csv = pd.read_csv(csv_path)\n",
        "\n",
        "    clips = np.array(csv['ClipID'])\n",
        "    Y = to_categorical(np.array(csv.iloc[:, 1 + emotion]) // (4 // num_classes), num_classes)\n",
        "\n",
        "    videos_test, labels_test, opface_test, xlabel_test = [], [], [], []\n",
        "\n",
        "    for Yi in range(len(clips)):\n",
        "        print(\"\\rCLIP {}/{}\".format(Yi, len(Y)), end=\"\")\n",
        "        file_name = clips[Yi].split(\".\")[0]\n",
        "        subject = file_name[:6]\n",
        "\n",
        "        dir_path = \"daisee/features/Test/{}/{}_aligned\".format(subject, file_name)\n",
        "        of_path = \"daisee/of_features/Test/{}/{}.csv\".format(subject, file_name)\n",
        "\n",
        "        files, filesof = [], []\n",
        "        \n",
        "        for i in range(1,350):\n",
        "            image_path = \"{}/frame_det_00_000{:03d}.jpg\".format(dir_path, i)\n",
        "            if os.path.isfile(image_path) and os.path.isfile(of_path):\n",
        "                files.append(image_path)\n",
        "                filesof.append(\"{}|{}\".format(of_path, i-1))\n",
        "\n",
        "        # append only the parts relative to the video section\n",
        "        last = (len(files) - time_frames*skip) // skip\n",
        "        rg = range(0, last + 1, np.max([1, int(stride * time_frames)]))\n",
        "        for i in rg:\n",
        "            temp, tpof = [], []\n",
        "            for j in range(i*skip, (i+time_frames)*skip, skip):\n",
        "                temp.append(files[j])\n",
        "                tpof.append(filesof[j])\n",
        "            videos_test.append(temp)\n",
        "            opface_test.append(tpof)\n",
        "            labels_test.append(Y[Yi])\n",
        "\n",
        "            xl = []\n",
        "            for l in range(Yi - 1, 0, -1):\n",
        "                sub2 = clips[l].split(\".\")[0][:6]\n",
        "                if subject == sub2:\n",
        "                    xl.append(Y[l])\n",
        "                if len(xl) == label_window:\n",
        "                    break\n",
        "\n",
        "            xl = [(xl[0] if len(xl) > 0 else np.array([0., 1.])) for x in range(label_window - len(xl))] + xl\n",
        "            xlabel_test.append(xl)\n",
        "\n",
        "\n",
        "    videos = [videos_test] + videos\n",
        "    opface = [opface_test] + opface\n",
        "    labels = [labels_test] + labels\n",
        "    xlabel = [xlabel_test] + xlabel\n",
        "\n",
        "    print(\"\\nDONE\")\n",
        "    return videos, opface, xlabel, labels\n",
        "\n",
        "\n",
        "def save_folds(folds, em):\n",
        "    !mkdir folds\n",
        "\n",
        "    first_only = False\n",
        "\n",
        "    folds_copy = folds.copy()\n",
        "\n",
        "    if len(folds) == 1:\n",
        "        test_X = folds_copy[0][0].pop(0)\n",
        "        test_XO = folds_copy[0][1].pop(0)\n",
        "        test_XL = folds_copy[0][2].pop(0)\n",
        "        test_Y = folds_copy[0][3].pop(0)\n",
        "\n",
        "        videos = folds_copy[0][0]\n",
        "        opface = folds_copy[0][1]\n",
        "        xlabel = folds_copy[0][2]\n",
        "        labels = folds_copy[0][3]\n",
        "\n",
        "    elif len(folds) == 2:\n",
        "        test_X = folds_copy[0][0].pop(0) + folds_copy[1][0].pop(0)\n",
        "        test_XO = folds_copy[0][1].pop(0) + folds_copy[1][1].pop(0)\n",
        "        test_XL = folds_copy[0][2].pop(0) + folds_copy[1][2].pop(0)\n",
        "        test_Y = folds_copy[0][3].pop(0) + folds_copy[1][3].pop(0)\n",
        "\n",
        "        videos = folds_copy[0][0] + folds_copy[1][0]\n",
        "        opface = folds_copy[0][1] + folds_copy[1][1]\n",
        "        xlabel = folds_copy[0][2] + folds_copy[1][2]\n",
        "        labels = folds_copy[0][3] + folds_copy[1][3]\n",
        "\n",
        "    test_Y = np.array(test_Y)\n",
        "    print(test_Y.shape)\n",
        "    np.save(\"folds/{}_test_Y.npy\".format(em), test_Y)\n",
        "    \n",
        "    test_X = np.array(test_X)\n",
        "    print(test_X.shape)\n",
        "    np.save(\"folds/{}_test_XV.npy\".format(em), test_X)\n",
        "\n",
        "    test_XO = np.array(test_XO)\n",
        "    print(test_XO.shape)\n",
        "    np.save(\"folds/{}_test_XO.npy\".format(em), test_XO)\n",
        "\n",
        "    test_XL = np.array(test_XL)\n",
        "    print(test_XL.shape)\n",
        "    np.save(\"folds/{}_test_XL.npy\".format(em), test_XL)\n",
        "\n",
        "    for i in range(n_folds):\n",
        "        print(\"SAVING FOLD {}...\".format(i+1))\n",
        "        train_X = videos.copy()\n",
        "        train_XO = opface.copy()\n",
        "        train_XL = xlabel.copy()\n",
        "        train_Y = labels.copy()\n",
        "\n",
        "        val_X = train_X.pop(i)\n",
        "        val_XO = train_XO.pop(i)\n",
        "        val_XL = train_XL.pop(i)\n",
        "        val_Y = train_Y.pop(i)\n",
        "\n",
        "        train_X = np.concatenate(train_X)\n",
        "        train_XO = np.concatenate(train_XO)\n",
        "        train_XL = np.concatenate(train_XL)\n",
        "        train_Y = np.concatenate(train_Y)\n",
        "\n",
        "        # create index array for resample\n",
        "        I = np.array([x for x in range(len(train_X))]).reshape(-1,1)\n",
        "\n",
        "        # I, train_Y = ros.fit_resample(I, train_Y)\n",
        "        # I, train_Y = rus.fit_resample(I, train_Y)\n",
        "        # train_Y = to_categorical(train_Y, len(original))\n",
        "\n",
        "        # copy resampled elements from original arrays according to resampling indexes\n",
        "        ntx, ntxo, ntxl = [], [], []\n",
        "        for x in I:\n",
        "            ntx.append(train_X[x[0]])\n",
        "            ntxo.append(train_XO[x[0]])\n",
        "            ntxl.append(train_XL[x[0]])\n",
        "        train_X = ntx\n",
        "        train_XO = ntxo\n",
        "        train_XL = ntxl\n",
        "\n",
        "        # save folds to file\n",
        "        train_Y = np.array(train_Y)\n",
        "        print(train_Y.shape)\n",
        "        np.save(\"folds/{}_fold_{}_train_Y.npy\".format(em, i), train_Y)\n",
        "        \n",
        "        train_X = np.array(train_X)\n",
        "        print(train_X.shape)\n",
        "        np.save(\"folds/{}_fold_{}_train_XV.npy\".format(em, i), train_X)\n",
        "\n",
        "        train_XO = np.array(train_XO)\n",
        "        print(train_XO.shape)\n",
        "        np.save(\"folds/{}_fold_{}_train_XO.npy\".format(em, i), train_XO)\n",
        "\n",
        "        train_XL = np.array(train_XL)\n",
        "        print(train_XL.shape)\n",
        "        np.save(\"folds/{}_fold_{}_train_XL.npy\".format(em, i), train_XL)\n",
        "\n",
        "        val_Y = np.array(val_Y)\n",
        "        print(val_Y.shape)\n",
        "        np.save(\"folds/{}_fold_{}_validation_Y.npy\".format(em, i), val_Y)\n",
        "        \n",
        "        val_X = np.array(val_X)\n",
        "        print(val_X.shape)\n",
        "        np.save(\"folds/{}_fold_{}_validation_XV.npy\".format(em, i), val_X)\n",
        "\n",
        "        val_XO = np.array(val_XO)\n",
        "        print(val_XO.shape)\n",
        "        np.save(\"folds/{}_fold_{}_validation_XO.npy\".format(em, i), val_XO)\n",
        "\n",
        "        val_XL = np.array(val_XL)\n",
        "        print(val_XL.shape)\n",
        "        np.save(\"folds/{}_fold_{}_validation_XL.npy\".format(em, i), val_XL)\n",
        "\n",
        "        if first_only:\n",
        "            break\n",
        "\n",
        "\n",
        "class Generator_V(Sequence):\n",
        "    def __init__(self, gen_split, batch_size, frames, emotion):\n",
        "        print(\"BUILDING GENERATOR...\")\n",
        "        self.batch_size = batch_size \n",
        "        self.labels, self.videos, = [], []\n",
        "        self.loadedOF = {}\n",
        "\n",
        "        file_prefix = \"\" if gen_split == \"Test\" else \"fold_{}_\".format(fold_step-1)\n",
        "        self.videos = np.load(\"folds/{}_{}{}_XV.npy\".format(emotion, file_prefix, gen_split.lower()))\n",
        "        self.opface = np.load(\"folds/{}_{}{}_XO.npy\".format(emotion, file_prefix, gen_split.lower()))\n",
        "        self.xlabel = np.load(\"folds/{}_{}{}_XL.npy\".format(emotion, file_prefix, gen_split.lower()))\n",
        "        self.labels = np.load(\"folds/{}_{}{}_Y.npy\".format(emotion, file_prefix, gen_split.lower()))\n",
        "\n",
        "        # self.videos, self.labels = shuffle(self.videos, self.labels, random_state=0)\n",
        "        print(\"Done\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.videos) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_xv = self.videos[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_xo = self.opface[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_xl = self.xlabel[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "        videos, opface = [], []\n",
        "        for video in batch_xv:\n",
        "            images = []\n",
        "            for name in video:\n",
        "                img = cv2.imread(name)\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "                images.append(img/255)\n",
        "            videos.append(np.array(images))\n",
        "\n",
        "        for video in batch_xo:\n",
        "            images = []\n",
        "\n",
        "            of_path = video[0].split(\"|\")[0]\n",
        "            if not of_path in self.loadedOF:\n",
        "                csv_of = pd.read_csv(of_path)\n",
        "                rows = csv_of[[' gaze_0_x',' gaze_0_y',' gaze_0_z',' gaze_1_x',' gaze_1_y',' gaze_1_z',' gaze_angle_x',' gaze_angle_y',' pose_Tx',' pose_Ty',' pose_Tz',' pose_Rx',' pose_Ry',' pose_Rz',' AU01_r',' AU02_r',' AU04_r',' AU05_r',' AU06_r',' AU07_r',' AU09_r',' AU10_r',' AU12_r',' AU14_r',' AU15_r',' AU17_r',' AU20_r',' AU23_r',' AU25_r',' AU26_r',' AU45_r',' AU01_c',' AU02_c',' AU04_c',' AU05_c',' AU06_c',' AU07_c',' AU09_c',' AU10_c',' AU12_c',' AU14_c',' AU15_c',' AU17_c',' AU20_c',' AU23_c',' AU25_c',' AU26_c',' AU28_c',' AU45_c']]\n",
        "                min_max_scaler = MinMaxScaler()\n",
        "                self.loadedOF[of_path] = min_max_scaler.fit_transform(rows)\n",
        "\n",
        "            rows = self.loadedOF[of_path]\n",
        "\n",
        "            for name in video:\n",
        "                i = int(name.split(\"|\")[1])\n",
        "                try:\n",
        "                    img = rows[i]\n",
        "                except:\n",
        "                    print(\"ERROR\", i, len(rows))\n",
        "                images.append(img)\n",
        "\n",
        "            opface.append(np.array(images))\n",
        "\n",
        "        # videos = np.expand_dims(videos, axis=4)\n",
        "        videos = np.array(videos)\n",
        "        opface = np.array(opface)\n",
        "        xlabel = np.array(batch_xl)\n",
        "        label = np.array(batch_y)\n",
        "\n",
        "        # regressor\n",
        "        # label = np.array(batch_y).argmax(axis=1) / 3\n",
        "\n",
        "        return [videos, opface, xlabel], label\n",
        "        # return videos, label\n",
        "        # return opface, label\n",
        "\n",
        "def avgacc(y_true, y_pred):\n",
        "    def get_class_acc(id):\n",
        "        class_id_true = K.argmax(y_true, axis=-1)\n",
        "        class_id_pred = K.argmax(y_pred, axis=-1)\n",
        "        # Replace class_id_preds with class_id_true for recall here\n",
        "        accuracy_mask = K.cast(K.equal(class_id_pred, id), 'int32')\n",
        "        class_acc_tensor = K.cast(K.equal(class_id_true, class_id_pred), 'int32') * accuracy_mask\n",
        "        class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
        "        return class_acc\n",
        "\n",
        "    return sum([get_class_acc(0), get_class_acc(1)]) / 2\n",
        "\n",
        "\n",
        "def build_model(epoch=0, print_model=False):\n",
        "    from tcn import TCN, tcn_full_summary\n",
        "\n",
        "    img_size = 224\n",
        "    of_features = 49\n",
        "\n",
        "    def model_convlstm(input):\n",
        "        filters = 256\n",
        "\n",
        "        x = ConvLSTM2D(filters, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(5e-4), recurrent_regularizer=l2(1e-6), return_sequences=True)(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = ConvLSTM2D(filters, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(5e-4), recurrent_regularizer=l2(1e-6), return_sequences=False)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x)\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def model_openface(input):\n",
        "        filters = 1024\n",
        "\n",
        "        x = TCN(filters)(input)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def model_inception(input):\n",
        "        inception = tf.keras.applications.InceptionResNetV2(\n",
        "            input_shape = (img_size, img_size, 3),\n",
        "            weights = 'imagenet',\n",
        "            include_top = False\n",
        "        )\n",
        "\n",
        "        for layer in inception.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        x = TimeDistributed(inception)(input)\n",
        "\n",
        "        return x\n",
        "\n",
        "    print(\"Building model...\")\n",
        "    ########### IF BUILT, MUST DEFINE A NAME TO APPEND TO DIRECTORY NAME ###############\n",
        "    global ident_name\n",
        "\n",
        "    ########### IF LOADED, MUST DEFINE DIR NAME AND STARTING EPOCH ############\n",
        "    global dir_name\n",
        "\n",
        "    if not epoch:\n",
        "        input_v = Input(shape=(time_frames, img_size, img_size, 3))\n",
        "        input_o = Input(shape=(time_frames, of_features))\n",
        "        input_l = Input(shape=(time_frames, 2))\n",
        "\n",
        "        mv = model_inception(input_v)\n",
        "        mv = model_convlstm(mv)\n",
        "        mo = model_openface(input_o)\n",
        "        ml = model_openface(input_l)\n",
        "\n",
        "        # joint model\n",
        "        x = Concatenate()([mv, mo, ml])\n",
        "        \n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.8)(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.8)(x)\n",
        "        x = Dense(2, activation='softmax')(x)\n",
        "\n",
        "        model = Model([input_v, input_o, input_l], x)\n",
        "        # model = Model(input_v, x)\n",
        "\n",
        "        model.compile(\n",
        "            # loss='mse',\n",
        "            loss='categorical_crossentropy',\n",
        "            optimizer = SGD(learning_rate=0.0001, momentum=0.9), \n",
        "            # optimizer = Adam(learning_rate=1e-4),\n",
        "            # metrics=[avgacc,'accuracy'])\n",
        "            # metrics=['mse'])\n",
        "            metrics=['accuracy'])\n",
        "    \n",
        "        t = datetime.datetime.now()\n",
        "        prefix = str(t.year) +'-'+ str(t.month) +'-'+ str(t.day) +'-'+ str(t.hour) +'-'+ str(t.minute) +'-'+ str(t.second)\n",
        "        save_dir = \"{}/{}-{}\".format(drive_save_path, prefix, ident_name)\n",
        "        os.mkdir(save_dir)\n",
        "    else:\n",
        "        file_name = \"{:03d}.h5\".format(epoch)\n",
        "        save_dir = \"{}/{}\".format(drive_save_path, dir_name)\n",
        "        print(\"Loading model from {}/{}.\".format(save_dir, file_name))\n",
        "        model = load_model(\"{}/{}\".format(save_dir, file_name), custom_objects={'TCN': TCN, 'avgacc': avgacc})\n",
        "\n",
        "    if print_model:\n",
        "        plot_model(model, show_layer_names=False, show_shapes=True, expand_nested=True)\n",
        "        display(Image('model.png'))\n",
        "\n",
        "    return model, save_dir, epoch\n",
        "\n",
        "\n",
        "def set_callbacks():\n",
        "    #callbacks\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath = save_dir + '/{epoch:03d}.h5', \n",
        "        monitor = 'val_loss', \n",
        "        verbose=1, \n",
        "        save_best_only=True,\n",
        "    )\n",
        "\n",
        "    tensorboard = TensorBoard(\n",
        "    \tlog_dir         = \"{}/logs\".format(save_dir),\n",
        "    \thistogram_freq  = 0,\n",
        "    \twrite_graph     = True,\n",
        "    \twrite_grads     = False,\n",
        "    \twrite_images    = True\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor \t= 'val_loss',\n",
        "        patience \t= 20,\n",
        "        restore_best_weights = True,\n",
        "        verbose     = 1,\n",
        "        min_delta   = 1e-5\n",
        "    )\n",
        "\n",
        "    reduce_lr_plateau = ReduceLROnPlateau(\n",
        "        monitor \t= 'val_loss',\n",
        "        factor\t\t= 0.5,\n",
        "        patience\t= 10,\n",
        "        min_lr\t\t= 1e-6,\n",
        "        verbose     = 1\n",
        "    )\n",
        "\n",
        "    # return [checkpoint, tensorboard]\n",
        "    return [checkpoint, early_stop, reduce_lr_plateau, tensorboard]\n",
        "\n",
        "\n",
        "def fit_model(train_weights, epoch=0):\n",
        "    #calculate weights based on train set distribution\n",
        "    num_classes = len(train_weights)\n",
        "    if train_weights == [1 for x in range(num_classes)]:\n",
        "        weights = {x:1 for x in range(num_classes)}\n",
        "    else:\n",
        "        weights = {x: train_weights[x] for x in range(len(train_weights))}\n",
        "        print(\"Train weights: {}\".format(weights))\n",
        "\n",
        "    def run():\n",
        "        #run the model\n",
        "        return model.fit(\n",
        "            gen_train,\n",
        "            epochs = 1000,\n",
        "            validation_data = gen_val,\n",
        "            class_weight = weights,\n",
        "            callbacks = callbacks,\n",
        "            initial_epoch = epoch)\n",
        "        \n",
        "    hist = run()  \n",
        "\n",
        "    plot_hist(hist)\n",
        "\n",
        "    return hist\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history['loss'], '#0000ff', label=\"loss\")\n",
        "    plt.plot(hist.history['val_loss'], '#ff0000', label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['accuracy'], '#0000ff', label=\"acc\")\n",
        "    plt.plot(hist.history['val_accuracy'], '#ff0000', label=\"val_acc\")\n",
        "    # plt.plot(hist.history['accuracy'], '#0055aa', label=\"acc\")\n",
        "    # plt.plot(hist.history['val_accuracy'], '#aa5500', label=\"val_acc\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def predict(**kw):\n",
        "    global gen_test\n",
        "\n",
        "    Y_true = np.load(\"folds/{}_test_Y.npy\".format(emotion))\n",
        "    num_classes = Y_true.shape[1]\n",
        "    Y_true = Y_true.argmax(axis=1)\n",
        "\n",
        "    print(\"Predicting...\")\n",
        "    Y_pred = model.predict(gen_test, verbose=1).argmax(axis=1)\n",
        "    print(\"\\nConfusion matrix:\")\n",
        "    cm = confusion_matrix(Y_true, Y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "    ev = model.evaluate(gen_test, verbose=1)\n",
        "    # print(\"Loss: {}, Acc: {}\".format(ev[0], ev[1]))\n",
        "\n",
        "    hits = [0 for x in range(num_classes)]\n",
        "    total = [0 for x in range(num_classes)]\n",
        "    for i in range(len(Y_true)):\n",
        "        for c in range(num_classes):\n",
        "            if (Y_true[i] == c and Y_pred[i] == c):\n",
        "                hits[c] = hits[c] + 1\n",
        "            if Y_true[i] == c:\n",
        "                total[c] = total[c] + 1\n",
        "\n",
        "    print(\"\\nPer class accuracy:\")\n",
        "    for c in range(num_classes):\n",
        "        hits[c] = hits[c] / total[c]\n",
        "        print(\"{}: {}\".format(c, hits[c]))\n",
        "\n",
        "    print(\"Average class accuracy: {}\".format(sum(hits) / len(hits)))\n",
        "\n",
        "    f1 = f1_score(Y_true, Y_pred, average=None)\n",
        "    print(\"F1 score: {}. Avg F1: {}\".format(f1, np.mean(f1)))\n",
        "\n",
        "    return gen_test\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV90nmZmG7T_"
      },
      "outputs": [],
      "source": [
        "# IF EVER YOU NEED TO RECREATE THE FOLDS\n",
        "# emotionList = [\"engagement\", \"confusion\", \"frustration\", \"boredom\"]\n",
        "# for em in emotionList:\n",
        "#     fold_p2m = create_folds_p2m(em)\n",
        "#     fold_daisee = create_folds_daisee(em)\n",
        "#     save_folds([fold_p2m, fold_daisee], em)\n",
        "\n",
        "# !rm -f /content/drive/MyDrive/1NOSYNC/DT/folds.zip\n",
        "# !zip /content/drive/MyDrive/1NOSYNC/DT/folds.zip folds/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftk-6PF0BKTt"
      },
      "outputs": [],
      "source": [
        "# start_colab()\n",
        "# extract_data()\n",
        "# !unzip /content/drive/MyDrive/1NOSYNC/DT/folds.zip -d ./\n",
        "\n",
        "# fold_step = 1\n",
        "# emotion = 'frustration'\n",
        "# gen_train = Generator_V('Train', batch_size, time_frames, emotion)\n",
        "# gen_val = Generator_V('Validation', batch_size, time_frames, emotion)\n",
        "# gen_test = Generator_V('Test', batch_size, time_frames, emotion)\n",
        "\n",
        "# dir_name = '2022-8-6-14-4-29-final'\n",
        "# epoch = 25\n",
        "model, save_dir, epoch = build_model(epoch, print_model=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf2w1WiOBZMe",
        "outputId": "fb6e9631-23d5-4772-ccc9-83c667e010cd"
      },
      "outputs": [],
      "source": [
        "# callbacks = set_callbacks()\n",
        "# fit_model(list(len(gen_train.labels) / np.sum(gen_train.labels, axis=0)), epoch)\n",
        "gen_test = predict()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
