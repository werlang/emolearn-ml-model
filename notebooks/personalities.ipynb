{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "personalities.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOwulxBLLSbIVb5DWtnbbEQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werlang/emolearn-ml-model/blob/main/personalities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwpi09Jo6O2S"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence, plot_model, to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import TimeDistributed, GRU, LSTM, Dropout, Conv1D, Conv2D, Conv3D, ConvLSTM2D, BatchNormalization, MaxPooling1D, MaxPooling2D, MaxPooling3D, GlobalAveragePooling2D, Flatten, Dense, Input, Add, Activation, AveragePooling3D, AveragePooling2D, ZeroPadding3D, Bidirectional, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, cv2\n",
        "import datetime\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from numba import cuda\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "import functools\n",
        "\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# sm = SMOTE(sampling_strategy=0.6666)\n",
        "# X, y = sm.fit_resample(X, y)\n",
        "\n",
        "\n",
        "drive_save_path = 'drive/My Drive/1NOSYNC/DT/checkpoint'\n",
        "ident_name = 'personality'\n",
        "dir_name = '2021-12-9-2-44-8-personality'\n",
        "batch_size = 50\n",
        "time_frames = 20\n",
        "interval = 2\n",
        "stride = 1\n",
        "fold_step = 1\n",
        "n_folds = 10\n",
        "\n",
        "epoch = 0\n",
        "\n",
        "\n",
        "def restart():\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "\n",
        "\n",
        "def start_colab():\n",
        "    from google.colab import drive\n",
        "    drive._mount('/content/drive', force_remount=True)\n",
        "    !pip install Keras-Applications\n",
        "    # !pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "    !pip install keras-tcn\n",
        "\n",
        "\n",
        "def extract_data():\n",
        "    !mkdir p2m\n",
        "    !mkdir p2m/features\n",
        "\n",
        "    # aligned faces extracted from openface\n",
        "    print(\"COPYING ALIGNED FACES...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/p2m_faces.zip\" -d p2m/features\n",
        "    print(\"COPYING OPENFACE FEATURES...\")\n",
        "    !unzip -n -q \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/p2m_openface.zip\" -d p2m/features\n",
        "    print(\"COPYING LABELS...\")\n",
        "    !cp -r \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/labels.csv\" p2m\n",
        "    !cp -r \"drive/My Drive/1NOSYNC/DT/p2m_dataset/224/personalities.csv\" p2m\n",
        "\n",
        "    print(\"P2M DONE\")\n",
        "\n",
        "\n",
        "def create_folds_p2m():\n",
        "    num_classes = 2\n",
        "    label_window = time_frames\n",
        "    print(\"CREATING FOLDS...\")\n",
        "    subs = {}\n",
        "\n",
        "    csv = pd.read_csv('p2m/labels.csv')\n",
        "    Y = np.array(csv.iloc[:,3])\n",
        "    subjects = np.array(csv['SUBJECT'])\n",
        "    clips = np.array(csv['CLIP'])\n",
        "    source_frames = np.array(csv['SOURCE_FRAMES'])\n",
        "\n",
        "    Y = to_categorical(Y, num_classes)    \n",
        "\n",
        "    for i in range(len(subjects)):\n",
        "        if not subjects[i] in subs:\n",
        "            subs[subjects[i]] = [0 for x in range(num_classes)]\n",
        "        subs[subjects[i]] = np.add(subs[subjects[i]], Y[i])\n",
        "\n",
        "    # total = np.sum(Y, axis=0)\n",
        "    # print(total, total / len(Y))\n",
        "    # print(subs)\n",
        "\n",
        "    folds = []\n",
        "    fold_names = []\n",
        "    for i in subs:\n",
        "        if len(folds) < n_folds + 1:\n",
        "            folds.append(subs[i])\n",
        "            fold_names.append([i])\n",
        "        else:\n",
        "            summed = np.sum(folds, axis=1)\n",
        "            index = list(summed).index(min(summed))\n",
        "            folds[index] = np.add(folds[index], subs[i])\n",
        "            fold_names[index].append(i)\n",
        "\n",
        "    # print(folds)\n",
        "    # print(fold_names)\n",
        "    # print(np.sum(folds, axis=1))\n",
        "\n",
        "    # print(\"GETTING FOLDS DATA...\")\n",
        "    # build frames array\n",
        "    videos, labels, opface, xlabel, pers = [], [], [], [], []\n",
        "    for i in range(len(fold_names)):\n",
        "        videos.append([])\n",
        "        opface.append([])\n",
        "        labels.append([])\n",
        "        xlabel.append([])\n",
        "        pers.append([])\n",
        "\n",
        "    fps = 30\n",
        "    skip = int(round(interval * fps / time_frames, 0))\n",
        "\n",
        "    # pick personalities csv and scale\n",
        "    personality_csv = pd.read_csv('p2m/personalities.csv')\n",
        "    personality_csv = np.array(personality_csv)[:,1:]\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    personality_csv = min_max_scaler.fit_transform(personality_csv)\n",
        "\n",
        "    for Yi in range(len(Y)):\n",
        "        print(\"\\rCLIP {}/{}\".format(Yi, len(Y)), end=\"\")\n",
        "        clip = clips[Yi]\n",
        "        start_frame = source_frames[Yi].split(\"-\")[0]\n",
        "        subject = subjects[Yi]\n",
        "        subject_personality = personality_csv[int(subject)]\n",
        "\n",
        "        for f in range(n_folds + 1):\n",
        "            if int(subject) in fold_names[f]:\n",
        "                files, filesof = [], []\n",
        "                \n",
        "                of_path = \"p2m/features/{:02}.csv\".format(subject)\n",
        "\n",
        "                for i in range(60):\n",
        "                    image_path = \"p2m/features/faces/{:02}.{:03}.{:02}.jpg\".format(subject, clip, i)\n",
        "                    \n",
        "                    if os.path.isfile(image_path) and os.path.isfile(of_path):\n",
        "                        files.append(image_path)\n",
        "                        filesof.append(\"{}|{}\".format(of_path, int(start_frame) + i))\n",
        "\n",
        "                # append only the parts relative to the video section\n",
        "                last = (len(files) - time_frames*skip) // skip\n",
        "                rg = range(0, last + 1, np.max([1, int(stride * time_frames)]))\n",
        "                for i in rg:\n",
        "                    temp, tpof = [], []\n",
        "                    for j in range(i*skip, (i+time_frames)*skip, skip):\n",
        "                        temp.append(files[j])\n",
        "                        tpof.append(filesof[j])\n",
        "                    videos[f].append(temp)\n",
        "                    opface[f].append(tpof)\n",
        "                    labels[f].append(Y[Yi])\n",
        "\n",
        "                    # get previous clip labels from same subject\n",
        "                    xl = []\n",
        "                    for l in range(Yi - 1, 0, -1):\n",
        "                        sub2 = subjects[l]\n",
        "                        if subject == sub2:\n",
        "                            xl.append(Y[l])\n",
        "                        if len(xl) == label_window:\n",
        "                            break\n",
        "                        \n",
        "                    xl = [(xl[0] if len(xl) > 0 else np.array([0., 1.])) for x in range(label_window - len(xl))] + xl\n",
        "                    xlabel[f].append(xl)\n",
        "\n",
        "                    xp = np.array([subject_personality for x in range(label_window)])\n",
        "                    pers[f].append(xp)\n",
        "\n",
        "\n",
        "    print(\"\\nDONE\")\n",
        "    return videos, opface, xlabel, pers, labels\n",
        "\n",
        "\n",
        "def save_folds(folds):\n",
        "    !mkdir folds\n",
        "\n",
        "    first_only = True\n",
        "\n",
        "    folds_copy = folds.copy()\n",
        "\n",
        "    if len(folds) == 1:\n",
        "        test_X = folds_copy[0][0].pop(0)\n",
        "        test_XO = folds_copy[0][1].pop(0)\n",
        "        test_XL = folds_copy[0][2].pop(0)\n",
        "        test_XP = folds_copy[0][3].pop(0)\n",
        "        test_Y = folds_copy[0][4].pop(0)\n",
        "\n",
        "        videos = folds_copy[0][0]\n",
        "        opface = folds_copy[0][1]\n",
        "        xlabel = folds_copy[0][2]\n",
        "        person = folds_copy[0][3]\n",
        "        labels = folds_copy[0][4]\n",
        "\n",
        "    test_Y = np.array(test_Y)\n",
        "    print(test_Y.shape)\n",
        "    np.save(\"folds/test_Y.npy\", test_Y)\n",
        "    \n",
        "    test_X = np.array(test_X)\n",
        "    print(test_X.shape)\n",
        "    np.save(\"folds/test_XV.npy\", test_X)\n",
        "\n",
        "    test_XO = np.array(test_XO)\n",
        "    print(test_XO.shape)\n",
        "    np.save(\"folds/test_XO.npy\", test_XO)\n",
        "\n",
        "    test_XL = np.array(test_XL)\n",
        "    print(test_XL.shape)\n",
        "    np.save(\"folds/test_XL.npy\", test_XL)\n",
        "\n",
        "    test_XP = np.array(test_XP)\n",
        "    print(test_XP.shape)\n",
        "    np.save(\"folds/test_XP.npy\", test_XP)\n",
        "\n",
        "    for i in range(n_folds):\n",
        "        print(\"SAVING FOLD {}...\".format(i+1))\n",
        "        train_X = videos.copy()\n",
        "        train_XO = opface.copy()\n",
        "        train_XL = xlabel.copy()\n",
        "        train_XP = person.copy()\n",
        "        train_Y = labels.copy()\n",
        "\n",
        "        val_X = train_X.pop(i)\n",
        "        val_XO = train_XO.pop(i)\n",
        "        val_XL = train_XL.pop(i)\n",
        "        val_XP = train_XP.pop(i)\n",
        "        val_Y = train_Y.pop(i)\n",
        "\n",
        "        train_X = np.concatenate(train_X)\n",
        "        train_XO = np.concatenate(train_XO)\n",
        "        train_XL = np.concatenate(train_XL)\n",
        "        train_XP = np.concatenate(train_XP)\n",
        "        train_Y = np.concatenate(train_Y)\n",
        "\n",
        "        # create index array for resample\n",
        "        I = np.array([x for x in range(len(train_X))]).reshape(-1,1)\n",
        "\n",
        "        # I, train_Y = ros.fit_resample(I, train_Y)\n",
        "        # I, train_Y = rus.fit_resample(I, train_Y)\n",
        "        # train_Y = to_categorical(train_Y, len(original))\n",
        "\n",
        "        # copy resampled elements from original arrays according to resampling indexes\n",
        "        ntx, ntxo, ntxl, ntxp = [], [], [], []\n",
        "        for x in I:\n",
        "            ntx.append(train_X[x[0]])\n",
        "            ntxo.append(train_XO[x[0]])\n",
        "            ntxl.append(train_XL[x[0]])\n",
        "            ntxp.append(train_XP[x[0]])\n",
        "        train_X = ntx\n",
        "        train_XO = ntxo\n",
        "        train_XL = ntxl\n",
        "        train_XP = ntxp\n",
        "\n",
        "        # save folds to file\n",
        "        train_Y = np.array(train_Y)\n",
        "        print(train_Y.shape)\n",
        "        np.save(\"folds/fold_{}_train_Y.npy\".format(i), train_Y)\n",
        "        \n",
        "        train_X = np.array(train_X)\n",
        "        print(train_X.shape)\n",
        "        np.save(\"folds/fold_{}_train_XV.npy\".format(i), train_X)\n",
        "\n",
        "        train_XO = np.array(train_XO)\n",
        "        print(train_XO.shape)\n",
        "        np.save(\"folds/fold_{}_train_XO.npy\".format(i), train_XO)\n",
        "\n",
        "        train_XL = np.array(train_XL)\n",
        "        print(train_XL.shape)\n",
        "        np.save(\"folds/fold_{}_train_XL.npy\".format(i), train_XL)\n",
        "        \n",
        "        train_XP = np.array(train_XP)\n",
        "        print(train_XP.shape)\n",
        "        np.save(\"folds/fold_{}_train_XP.npy\".format(i), train_XP)\n",
        "\n",
        "        val_Y = np.array(val_Y)\n",
        "        print(val_Y.shape)\n",
        "        np.save(\"folds/fold_{}_validation_Y.npy\".format(i), val_Y)\n",
        "        \n",
        "        val_X = np.array(val_X)\n",
        "        print(val_X.shape)\n",
        "        np.save(\"folds/fold_{}_validation_XV.npy\".format(i), val_X)\n",
        "\n",
        "        val_XO = np.array(val_XO)\n",
        "        print(val_XO.shape)\n",
        "        np.save(\"folds/fold_{}_validation_XO.npy\".format(i), val_XO)\n",
        "\n",
        "        val_XL = np.array(val_XL)\n",
        "        print(val_XL.shape)\n",
        "        np.save(\"folds/fold_{}_validation_XL.npy\".format(i), val_XL)\n",
        "\n",
        "        val_XP = np.array(val_XP)\n",
        "        print(val_XP.shape)\n",
        "        np.save(\"folds/fold_{}_validation_XP.npy\".format(i), val_XP)\n",
        "\n",
        "        if first_only:\n",
        "            break\n",
        "\n",
        "\n",
        "class Generator_V(Sequence):\n",
        "    def __init__(self, gen_split, batch_size, frames):\n",
        "        print(\"BUILDING GENERATOR...\")\n",
        "        self.batch_size = batch_size \n",
        "        self.labels, self.videos, = [], []\n",
        "        self.loadedOF = {}\n",
        "\n",
        "        file_prefix = \"\" if gen_split == \"Test\" else \"fold_{}_\".format(fold_step-1)\n",
        "        self.videos = np.load(\"folds/{}{}_XV.npy\".format(file_prefix, gen_split.lower()))\n",
        "        self.opface = np.load(\"folds/{}{}_XO.npy\".format(file_prefix, gen_split.lower()))\n",
        "        self.xlabel = np.load(\"folds/{}{}_XL.npy\".format(file_prefix, gen_split.lower()))\n",
        "        self.person = np.load(\"folds/{}{}_XP.npy\".format(file_prefix, gen_split.lower()))\n",
        "        self.labels = np.load(\"folds/{}{}_Y.npy\".format(file_prefix, gen_split.lower()))\n",
        "\n",
        "        # self.videos, self.labels = shuffle(self.videos, self.labels, random_state=0)\n",
        "        print(\"Done\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.videos) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_xv = self.videos[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_xo = self.opface[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_xl = self.xlabel[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_xp = self.person[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "        videos, opface = [], []\n",
        "        for video in batch_xv:\n",
        "            images = []\n",
        "            for name in video:\n",
        "                img = cv2.imread(name)\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "                images.append(img/255)\n",
        "            videos.append(np.array(images))\n",
        "\n",
        "        for video in batch_xo:\n",
        "            images = []\n",
        "\n",
        "            of_path = video[0].split(\"|\")[0]\n",
        "            if not of_path in self.loadedOF:\n",
        "                csv_of = pd.read_csv(of_path)\n",
        "                rows = csv_of[[' gaze_0_x',' gaze_0_y',' gaze_0_z',' gaze_1_x',' gaze_1_y',' gaze_1_z',' gaze_angle_x',' gaze_angle_y',' pose_Tx',' pose_Ty',' pose_Tz',' pose_Rx',' pose_Ry',' pose_Rz',' AU01_r',' AU02_r',' AU04_r',' AU05_r',' AU06_r',' AU07_r',' AU09_r',' AU10_r',' AU12_r',' AU14_r',' AU15_r',' AU17_r',' AU20_r',' AU23_r',' AU25_r',' AU26_r',' AU45_r',' AU01_c',' AU02_c',' AU04_c',' AU05_c',' AU06_c',' AU07_c',' AU09_c',' AU10_c',' AU12_c',' AU14_c',' AU15_c',' AU17_c',' AU20_c',' AU23_c',' AU25_c',' AU26_c',' AU28_c',' AU45_c']]\n",
        "                min_max_scaler = MinMaxScaler()\n",
        "                self.loadedOF[of_path] = min_max_scaler.fit_transform(rows)\n",
        "\n",
        "            rows = self.loadedOF[of_path]\n",
        "\n",
        "            for name in video:\n",
        "                i = int(name.split(\"|\")[1])\n",
        "                try:\n",
        "                    img = rows[i]\n",
        "                except:\n",
        "                    print(\"ERROR\", i, len(rows))\n",
        "                images.append(img)\n",
        "\n",
        "            opface.append(np.array(images))\n",
        "\n",
        "        videos = np.array(videos)\n",
        "        opface = np.array(opface)\n",
        "        xlabel = np.array(batch_xl)\n",
        "        person = np.array(batch_xp)\n",
        "        label = np.array(batch_y)\n",
        "\n",
        "        # return [videos, opface, xlabel, person], label\n",
        "        # return [videos, opface, xlabel], label\n",
        "        return [videos, opface], label\n",
        "\n",
        "\n",
        "def build_model(epoch=0, print_model=False):\n",
        "    from tcn import TCN, tcn_full_summary\n",
        "\n",
        "    img_size = 224\n",
        "    of_features = 49\n",
        "\n",
        "    def model_convlstm(input):\n",
        "        filters = 256\n",
        "\n",
        "        x = ConvLSTM2D(filters, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(5e-4), recurrent_regularizer=l2(1e-6), return_sequences=True)(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = ConvLSTM2D(filters, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(5e-4), recurrent_regularizer=l2(1e-6), return_sequences=False)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x)\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def model_tcn(input):\n",
        "        filters = 512\n",
        "\n",
        "        x = TCN(filters)(input)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def model_inception(input):\n",
        "        inception = tf.keras.applications.InceptionResNetV2(\n",
        "            input_shape = (img_size, img_size, 3),\n",
        "            weights = 'imagenet',\n",
        "            include_top = False\n",
        "        )\n",
        "\n",
        "        for layer in inception.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        x = TimeDistributed(inception)(input)\n",
        "\n",
        "        return x\n",
        "\n",
        "    print(\"Building model...\")\n",
        "    ########### IF BUILT, MUST DEFINE A NAME TO APPEND TO DIRECTORY NAME ###############\n",
        "    global ident_name\n",
        "\n",
        "    ########### IF LOADED, MUST DEFINE DIR NAME AND STARTING EPOCH ############\n",
        "    global dir_name\n",
        "\n",
        "    if not epoch:\n",
        "        input_v = Input(shape=(time_frames, img_size, img_size, 3))\n",
        "        input_o = Input(shape=(time_frames, of_features))\n",
        "        # input_l = Input(shape=(time_frames, 2))\n",
        "        # input_p = Input(shape=(time_frames, 5))\n",
        "\n",
        "        mv = model_inception(input_v)\n",
        "        mv = model_convlstm(mv)\n",
        "        mo = model_tcn(input_o)\n",
        "        # ml = model_tcn(input_l)\n",
        "        # mp = model_tcn(input_p)\n",
        "\n",
        "        # joint model\n",
        "        x = Concatenate()([mv, mo])\n",
        "        # x = Concatenate()([mv, mo, ml])\n",
        "        # x = Concatenate()([mv, mo, ml, mp])\n",
        "        \n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.8)(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.8)(x)\n",
        "        x = Dense(2, activation='softmax')(x)\n",
        "\n",
        "        model = Model([input_v, input_o], x)\n",
        "        # model = Model([input_v, input_o, input_l], x)\n",
        "        # model = Model([input_v, input_o, input_l, input_p], x)\n",
        "\n",
        "        model.compile(\n",
        "            loss='categorical_crossentropy',\n",
        "            optimizer = SGD(learning_rate=0.0001, momentum=0.9), \n",
        "            metrics=['accuracy'])\n",
        "    \n",
        "        t = datetime.datetime.now()\n",
        "        prefix = str(t.year) +'-'+ str(t.month) +'-'+ str(t.day) +'-'+ str(t.hour) +'-'+ str(t.minute) +'-'+ str(t.second)\n",
        "        save_dir = \"{}/{}-{}\".format(drive_save_path, prefix, ident_name)\n",
        "        os.mkdir(save_dir)\n",
        "    else:\n",
        "        file_name = \"{:03d}.h5\".format(epoch)\n",
        "        save_dir = \"{}/{}\".format(drive_save_path, dir_name)\n",
        "        print(\"Loading model from {}/{}.\".format(save_dir, file_name))\n",
        "        model = load_model(\"{}/{}\".format(save_dir, file_name), custom_objects={'TCN': TCN})\n",
        "\n",
        "    if print_model:\n",
        "        plot_model(model, show_layer_names=False, show_shapes=True, expand_nested=True)\n",
        "        # display(Image('model.png'))\n",
        "\n",
        "    return model, save_dir, epoch\n",
        "\n",
        "\n",
        "def set_callbacks():\n",
        "    #callbacks\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath = save_dir + '/{epoch:03d}.h5', \n",
        "        monitor = 'val_loss', \n",
        "        verbose=1, \n",
        "        save_best_only=True,\n",
        "    )\n",
        "\n",
        "    tensorboard = TensorBoard(\n",
        "    \tlog_dir         = \"{}/logs\".format(save_dir),\n",
        "    \thistogram_freq  = 0,\n",
        "    \twrite_graph     = True,\n",
        "    \twrite_grads     = False,\n",
        "    \twrite_images    = True\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor \t= 'val_loss',\n",
        "        patience \t= 20,\n",
        "        restore_best_weights = True,\n",
        "        verbose     = 1,\n",
        "        min_delta   = 1e-5\n",
        "    )\n",
        "\n",
        "    reduce_lr_plateau = ReduceLROnPlateau(\n",
        "        monitor \t= 'val_loss',\n",
        "        factor\t\t= 0.5,\n",
        "        patience\t= 10,\n",
        "        min_lr\t\t= 1e-6,\n",
        "        verbose     = 1\n",
        "    )\n",
        "\n",
        "    # return [checkpoint, tensorboard]\n",
        "    return [checkpoint, early_stop, reduce_lr_plateau, tensorboard]\n",
        "\n",
        "\n",
        "def fit_model(train_weights, epoch=0):\n",
        "    #calculate weights based on train set distribution\n",
        "    num_classes = len(train_weights)\n",
        "    if train_weights == [1 for x in range(num_classes)]:\n",
        "        weights = {x:1 for x in range(num_classes)}\n",
        "    else:\n",
        "        weights = {x: train_weights[x] for x in range(len(train_weights))}\n",
        "        print(\"Train weights: {}\".format(weights))\n",
        "\n",
        "    def run():\n",
        "        #run the model\n",
        "        return model.fit(\n",
        "            gen_train,\n",
        "            epochs = 1000,\n",
        "            validation_data = gen_val,\n",
        "            class_weight = weights,\n",
        "            callbacks = callbacks,\n",
        "            initial_epoch = epoch)\n",
        "        \n",
        "    hist = run()  \n",
        "\n",
        "    plot_hist(hist)\n",
        "\n",
        "    return hist\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history['loss'], '#0000ff', label=\"loss\")\n",
        "    plt.plot(hist.history['val_loss'], '#ff0000', label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(hist.history['accuracy'], '#0000ff', label=\"acc\")\n",
        "    plt.plot(hist.history['val_accuracy'], '#ff0000', label=\"val_acc\")\n",
        "    # plt.plot(hist.history['accuracy'], '#0055aa', label=\"acc\")\n",
        "    # plt.plot(hist.history['val_accuracy'], '#aa5500', label=\"val_acc\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def predict(**kw):\n",
        "    global gen_test\n",
        "\n",
        "    Y_true = np.load(\"folds/test_Y.npy\")\n",
        "    num_classes = Y_true.shape[1]\n",
        "    Y_true = Y_true.argmax(axis=1)\n",
        "\n",
        "    print(\"Predicting...\")\n",
        "    Y_pred = model.predict(gen_test, verbose=1).argmax(axis=1)\n",
        "    print(\"\\nConfusion matrix:\")\n",
        "    cm = confusion_matrix(Y_true, Y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "    ev = model.evaluate(gen_test, verbose=1)\n",
        "    # print(\"Loss: {}, Acc: {}\".format(ev[0], ev[1]))\n",
        "\n",
        "    hits = [0 for x in range(num_classes)]\n",
        "    total = [0 for x in range(num_classes)]\n",
        "    for i in range(len(Y_true)):\n",
        "        for c in range(num_classes):\n",
        "            if (Y_true[i] == c and Y_pred[i] == c):\n",
        "                hits[c] = hits[c] + 1\n",
        "            if Y_true[i] == c:\n",
        "                total[c] = total[c] + 1\n",
        "\n",
        "    print(\"\\nPer class accuracy:\")\n",
        "    for c in range(num_classes):\n",
        "        hits[c] = hits[c] / total[c]\n",
        "        print(\"{}: {}\".format(c, hits[c]))\n",
        "\n",
        "    print(\"Average class accuracy: {}\".format(sum(hits) / len(hits)))\n",
        "\n",
        "    f1 = f1_score(Y_true, Y_pred, average=None)\n",
        "    print(\"F1 score: {}. Avg F1: {}\".format(f1, np.mean(f1)))\n",
        "\n",
        "    return gen_test\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QmXyo3TVhQpV",
        "outputId": "e1f4fae1-4965-4a1a-ab78-4f8647f97bea"
      },
      "source": [
        "# restart()\n",
        "# start_colab()\n",
        "# extract_data()\n",
        "# fold_p2m = create_folds_p2m()\n",
        "# save_folds([fold_p2m])\n",
        "\n",
        "gen_train = Generator_V('Train', batch_size, time_frames)\n",
        "gen_val = Generator_V('Validation', batch_size, time_frames)\n",
        "gen_test = Generator_V('Test', batch_size, time_frames)\n",
        "\n",
        "model, save_dir, epoch = build_model(epoch, print_model=False)\n",
        "\n",
        "callbacks = set_callbacks()\n",
        "fit_model(list(len(gen_train.labels) / np.sum(gen_train.labels, axis=0)), epoch)\n",
        "gen_test = predict()\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "Building model...\n",
            "Train weights: {0: 2.5943563, 1: 1.6272124}\n",
            "Epoch 1/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 8.4959 - accuracy: 0.5078\n",
            "Epoch 00001: val_loss improved from inf to 1.52450, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/001.h5\n",
            "59/59 [==============================] - 173s 2s/step - loss: 8.4959 - accuracy: 0.5078 - val_loss: 1.5245 - val_accuracy: 0.4536 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2187 - accuracy: 0.5143\n",
            "Epoch 00002: val_loss improved from 1.52450 to 1.50685, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/002.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.2187 - accuracy: 0.5143 - val_loss: 1.5069 - val_accuracy: 0.6151 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1841 - accuracy: 0.6105\n",
            "Epoch 00003: val_loss improved from 1.50685 to 1.49666, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/003.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.1841 - accuracy: 0.6105 - val_loss: 1.4967 - val_accuracy: 0.7629 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1642 - accuracy: 0.6247\n",
            "Epoch 00004: val_loss did not improve from 1.49666\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1642 - accuracy: 0.6247 - val_loss: 1.5005 - val_accuracy: 0.7388 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1636 - accuracy: 0.6356\n",
            "Epoch 00005: val_loss improved from 1.49666 to 1.47658, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/005.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.1636 - accuracy: 0.6356 - val_loss: 1.4766 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1524 - accuracy: 0.6502\n",
            "Epoch 00006: val_loss improved from 1.47658 to 1.46760, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/006.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.1524 - accuracy: 0.6502 - val_loss: 1.4676 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1438 - accuracy: 0.6567\n",
            "Epoch 00007: val_loss did not improve from 1.46760\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1438 - accuracy: 0.6567 - val_loss: 1.4705 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1188 - accuracy: 0.6757\n",
            "Epoch 00008: val_loss did not improve from 1.46760\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.1188 - accuracy: 0.6757 - val_loss: 1.4942 - val_accuracy: 0.8282 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1071 - accuracy: 0.6832\n",
            "Epoch 00009: val_loss improved from 1.46760 to 1.42371, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/009.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.1071 - accuracy: 0.6832 - val_loss: 1.4237 - val_accuracy: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 10/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0888 - accuracy: 0.6982\n",
            "Epoch 00010: val_loss did not improve from 1.42371\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0888 - accuracy: 0.6982 - val_loss: 1.4344 - val_accuracy: 0.8110 - lr: 1.0000e-04\n",
            "Epoch 11/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0906 - accuracy: 0.6965\n",
            "Epoch 00011: val_loss did not improve from 1.42371\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0906 - accuracy: 0.6965 - val_loss: 1.4558 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
            "Epoch 12/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0876 - accuracy: 0.6757\n",
            "Epoch 00012: val_loss improved from 1.42371 to 1.40991, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/012.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 2.0876 - accuracy: 0.6757 - val_loss: 1.4099 - val_accuracy: 0.8247 - lr: 1.0000e-04\n",
            "Epoch 13/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0764 - accuracy: 0.6839\n",
            "Epoch 00013: val_loss did not improve from 1.40991\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0764 - accuracy: 0.6839 - val_loss: 1.4110 - val_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 14/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1139 - accuracy: 0.6747\n",
            "Epoch 00014: val_loss did not improve from 1.40991\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1139 - accuracy: 0.6747 - val_loss: 1.4800 - val_accuracy: 0.7560 - lr: 1.0000e-04\n",
            "Epoch 15/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0728 - accuracy: 0.7012\n",
            "Epoch 00015: val_loss improved from 1.40991 to 1.37277, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/015.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.0728 - accuracy: 0.7012 - val_loss: 1.3728 - val_accuracy: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 16/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0883 - accuracy: 0.6890\n",
            "Epoch 00016: val_loss did not improve from 1.37277\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0883 - accuracy: 0.6890 - val_loss: 1.3807 - val_accuracy: 0.8247 - lr: 1.0000e-04\n",
            "Epoch 17/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0542 - accuracy: 0.7155\n",
            "Epoch 00017: val_loss did not improve from 1.37277\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0542 - accuracy: 0.7155 - val_loss: 1.4500 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 18/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0434 - accuracy: 0.7121\n",
            "Epoch 00018: val_loss did not improve from 1.37277\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0434 - accuracy: 0.7121 - val_loss: 1.4732 - val_accuracy: 0.8110 - lr: 1.0000e-04\n",
            "Epoch 19/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0421 - accuracy: 0.7267\n",
            "Epoch 00019: val_loss improved from 1.37277 to 1.36360, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/019.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.0421 - accuracy: 0.7267 - val_loss: 1.3636 - val_accuracy: 0.8419 - lr: 1.0000e-04\n",
            "Epoch 20/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0091 - accuracy: 0.7379\n",
            "Epoch 00020: val_loss improved from 1.36360 to 1.35162, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/020.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 2.0091 - accuracy: 0.7379 - val_loss: 1.3516 - val_accuracy: 0.8660 - lr: 1.0000e-04\n",
            "Epoch 21/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9945 - accuracy: 0.7508\n",
            "Epoch 00021: val_loss did not improve from 1.35162\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9945 - accuracy: 0.7508 - val_loss: 1.3932 - val_accuracy: 0.8522 - lr: 1.0000e-04\n",
            "Epoch 22/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0009 - accuracy: 0.7366\n",
            "Epoch 00022: val_loss improved from 1.35162 to 1.34431, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/022.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 2.0009 - accuracy: 0.7366 - val_loss: 1.3443 - val_accuracy: 0.8488 - lr: 1.0000e-04\n",
            "Epoch 23/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9986 - accuracy: 0.7447\n",
            "Epoch 00023: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.9986 - accuracy: 0.7447 - val_loss: 1.3567 - val_accuracy: 0.8591 - lr: 1.0000e-04\n",
            "Epoch 24/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9639 - accuracy: 0.7508\n",
            "Epoch 00024: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9639 - accuracy: 0.7508 - val_loss: 1.3897 - val_accuracy: 0.8419 - lr: 1.0000e-04\n",
            "Epoch 25/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0014 - accuracy: 0.7441\n",
            "Epoch 00025: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0014 - accuracy: 0.7441 - val_loss: 1.3517 - val_accuracy: 0.8591 - lr: 1.0000e-04\n",
            "Epoch 26/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9591 - accuracy: 0.7644\n",
            "Epoch 00026: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.9591 - accuracy: 0.7644 - val_loss: 1.3845 - val_accuracy: 0.8625 - lr: 1.0000e-04\n",
            "Epoch 27/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9415 - accuracy: 0.7828\n",
            "Epoch 00027: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9415 - accuracy: 0.7828 - val_loss: 1.3912 - val_accuracy: 0.8454 - lr: 1.0000e-04\n",
            "Epoch 28/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9384 - accuracy: 0.7702\n",
            "Epoch 00028: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9384 - accuracy: 0.7702 - val_loss: 1.3470 - val_accuracy: 0.8488 - lr: 1.0000e-04\n",
            "Epoch 29/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9785 - accuracy: 0.7536\n",
            "Epoch 00029: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9785 - accuracy: 0.7536 - val_loss: 1.3683 - val_accuracy: 0.8660 - lr: 1.0000e-04\n",
            "Epoch 30/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9689 - accuracy: 0.7583\n",
            "Epoch 00030: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9689 - accuracy: 0.7583 - val_loss: 1.3566 - val_accuracy: 0.8454 - lr: 1.0000e-04\n",
            "Epoch 31/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9446 - accuracy: 0.7624\n",
            "Epoch 00031: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9446 - accuracy: 0.7624 - val_loss: 1.4016 - val_accuracy: 0.8488 - lr: 1.0000e-04\n",
            "Epoch 32/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9124 - accuracy: 0.7780\n",
            "Epoch 00032: val_loss did not improve from 1.34431\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9124 - accuracy: 0.7780 - val_loss: 1.3484 - val_accuracy: 0.8625 - lr: 1.0000e-04\n",
            "Epoch 33/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8927 - accuracy: 0.7937\n",
            "Epoch 00033: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8927 - accuracy: 0.7937 - val_loss: 1.3679 - val_accuracy: 0.8591 - lr: 5.0000e-05\n",
            "Epoch 34/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9062 - accuracy: 0.7964\n",
            "Epoch 00034: val_loss did not improve from 1.34431\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.9062 - accuracy: 0.7964 - val_loss: 1.3445 - val_accuracy: 0.8625 - lr: 5.0000e-05\n",
            "Epoch 35/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8701 - accuracy: 0.8175\n",
            "Epoch 00035: val_loss improved from 1.34431 to 1.31954, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/035.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.8701 - accuracy: 0.8175 - val_loss: 1.3195 - val_accuracy: 0.8797 - lr: 5.0000e-05\n",
            "Epoch 36/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8617 - accuracy: 0.8097\n",
            "Epoch 00036: val_loss did not improve from 1.31954\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.8617 - accuracy: 0.8097 - val_loss: 1.3239 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 37/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8434 - accuracy: 0.8076\n",
            "Epoch 00037: val_loss did not improve from 1.31954\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8434 - accuracy: 0.8076 - val_loss: 1.3515 - val_accuracy: 0.8660 - lr: 5.0000e-05\n",
            "Epoch 38/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8161 - accuracy: 0.8151\n",
            "Epoch 00038: val_loss did not improve from 1.31954\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8161 - accuracy: 0.8151 - val_loss: 1.3294 - val_accuracy: 0.8729 - lr: 5.0000e-05\n",
            "Epoch 39/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8297 - accuracy: 0.8209\n",
            "Epoch 00039: val_loss did not improve from 1.31954\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8297 - accuracy: 0.8209 - val_loss: 1.3211 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 40/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7896 - accuracy: 0.8266\n",
            "Epoch 00040: val_loss improved from 1.31954 to 1.30115, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/040.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.7896 - accuracy: 0.8266 - val_loss: 1.3011 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 41/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8117 - accuracy: 0.8154\n",
            "Epoch 00041: val_loss improved from 1.30115 to 1.29857, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/041.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.8117 - accuracy: 0.8154 - val_loss: 1.2986 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 42/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7926 - accuracy: 0.8205\n",
            "Epoch 00042: val_loss did not improve from 1.29857\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7926 - accuracy: 0.8205 - val_loss: 1.3236 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 43/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7884 - accuracy: 0.8199\n",
            "Epoch 00043: val_loss did not improve from 1.29857\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7884 - accuracy: 0.8199 - val_loss: 1.3036 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 44/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7845 - accuracy: 0.8307\n",
            "Epoch 00044: val_loss improved from 1.29857 to 1.29332, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/044.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.7845 - accuracy: 0.8307 - val_loss: 1.2933 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 45/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7652 - accuracy: 0.8338\n",
            "Epoch 00045: val_loss did not improve from 1.29332\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.7652 - accuracy: 0.8338 - val_loss: 1.3038 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 46/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7655 - accuracy: 0.8351\n",
            "Epoch 00046: val_loss did not improve from 1.29332\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.7655 - accuracy: 0.8351 - val_loss: 1.2984 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 47/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7625 - accuracy: 0.8283\n",
            "Epoch 00047: val_loss improved from 1.29332 to 1.29121, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/047.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.7625 - accuracy: 0.8283 - val_loss: 1.2912 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 48/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7518 - accuracy: 0.8280\n",
            "Epoch 00048: val_loss did not improve from 1.29121\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.7518 - accuracy: 0.8280 - val_loss: 1.2967 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 49/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7750 - accuracy: 0.8311\n",
            "Epoch 00049: val_loss improved from 1.29121 to 1.27651, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/049.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.7750 - accuracy: 0.8311 - val_loss: 1.2765 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 50/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7445 - accuracy: 0.8355\n",
            "Epoch 00050: val_loss did not improve from 1.27651\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.7445 - accuracy: 0.8355 - val_loss: 1.2958 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 51/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7319 - accuracy: 0.8450\n",
            "Epoch 00051: val_loss did not improve from 1.27651\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7319 - accuracy: 0.8450 - val_loss: 1.2874 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 52/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7339 - accuracy: 0.8368\n",
            "Epoch 00052: val_loss did not improve from 1.27651\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7339 - accuracy: 0.8368 - val_loss: 1.2877 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 53/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7497 - accuracy: 0.8392\n",
            "Epoch 00053: val_loss improved from 1.27651 to 1.25492, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/053.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.7497 - accuracy: 0.8392 - val_loss: 1.2549 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 54/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7221 - accuracy: 0.8447\n",
            "Epoch 00054: val_loss did not improve from 1.25492\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7221 - accuracy: 0.8447 - val_loss: 1.2955 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 55/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7030 - accuracy: 0.8484\n",
            "Epoch 00055: val_loss did not improve from 1.25492\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7030 - accuracy: 0.8484 - val_loss: 1.2768 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 56/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6853 - accuracy: 0.8518\n",
            "Epoch 00056: val_loss did not improve from 1.25492\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6853 - accuracy: 0.8518 - val_loss: 1.2673 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 57/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6851 - accuracy: 0.8491\n",
            "Epoch 00057: val_loss improved from 1.25492 to 1.25298, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/057.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.6851 - accuracy: 0.8491 - val_loss: 1.2530 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 58/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6637 - accuracy: 0.8545\n",
            "Epoch 00058: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.6637 - accuracy: 0.8545 - val_loss: 1.2914 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 59/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6710 - accuracy: 0.8549\n",
            "Epoch 00059: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6710 - accuracy: 0.8549 - val_loss: 1.2687 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 60/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6642 - accuracy: 0.8545\n",
            "Epoch 00060: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6642 - accuracy: 0.8545 - val_loss: 1.2726 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 61/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6678 - accuracy: 0.8576\n",
            "Epoch 00061: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6678 - accuracy: 0.8576 - val_loss: 1.2769 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 62/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6467 - accuracy: 0.8623\n",
            "Epoch 00062: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6467 - accuracy: 0.8623 - val_loss: 1.3077 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 63/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6506 - accuracy: 0.8600\n",
            "Epoch 00063: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6506 - accuracy: 0.8600 - val_loss: 1.2547 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 64/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6388 - accuracy: 0.8627\n",
            "Epoch 00064: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6388 - accuracy: 0.8627 - val_loss: 1.2696 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 65/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6259 - accuracy: 0.8719\n",
            "Epoch 00065: val_loss did not improve from 1.25298\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6259 - accuracy: 0.8719 - val_loss: 1.2586 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 66/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6260 - accuracy: 0.8661\n",
            "Epoch 00066: val_loss improved from 1.25298 to 1.23923, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/066.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.6260 - accuracy: 0.8661 - val_loss: 1.2392 - val_accuracy: 0.9003 - lr: 5.0000e-05\n",
            "Epoch 67/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6407 - accuracy: 0.8654\n",
            "Epoch 00067: val_loss did not improve from 1.23923\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6407 - accuracy: 0.8654 - val_loss: 1.2683 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 68/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6285 - accuracy: 0.8688\n",
            "Epoch 00068: val_loss did not improve from 1.23923\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6285 - accuracy: 0.8688 - val_loss: 1.2575 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 69/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5934 - accuracy: 0.8746\n",
            "Epoch 00069: val_loss did not improve from 1.23923\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5934 - accuracy: 0.8746 - val_loss: 1.2559 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 70/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6001 - accuracy: 0.8773\n",
            "Epoch 00070: val_loss did not improve from 1.23923\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6001 - accuracy: 0.8773 - val_loss: 1.2955 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 71/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5988 - accuracy: 0.8705\n",
            "Epoch 00071: val_loss improved from 1.23923 to 1.21840, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/071.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.5988 - accuracy: 0.8705 - val_loss: 1.2184 - val_accuracy: 0.9003 - lr: 5.0000e-05\n",
            "Epoch 72/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5988 - accuracy: 0.8719\n",
            "Epoch 00072: val_loss improved from 1.21840 to 1.21722, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/072.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.5988 - accuracy: 0.8719 - val_loss: 1.2172 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 73/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.8746\n",
            "Epoch 00073: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5875 - accuracy: 0.8746 - val_loss: 1.2604 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 74/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5652 - accuracy: 0.8763\n",
            "Epoch 00074: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5652 - accuracy: 0.8763 - val_loss: 1.2336 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 75/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5818 - accuracy: 0.8787\n",
            "Epoch 00075: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5818 - accuracy: 0.8787 - val_loss: 1.2514 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 76/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5615 - accuracy: 0.8851\n",
            "Epoch 00076: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5615 - accuracy: 0.8851 - val_loss: 1.2793 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 77/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5631 - accuracy: 0.8715\n",
            "Epoch 00077: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5631 - accuracy: 0.8715 - val_loss: 1.2216 - val_accuracy: 0.9003 - lr: 5.0000e-05\n",
            "Epoch 78/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5515 - accuracy: 0.8790\n",
            "Epoch 00078: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5515 - accuracy: 0.8790 - val_loss: 1.2463 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 79/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5303 - accuracy: 0.8804\n",
            "Epoch 00079: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.5303 - accuracy: 0.8804 - val_loss: 1.2564 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 80/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5338 - accuracy: 0.8906\n",
            "Epoch 00080: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5338 - accuracy: 0.8906 - val_loss: 1.2322 - val_accuracy: 0.9003 - lr: 5.0000e-05\n",
            "Epoch 81/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5301 - accuracy: 0.8889\n",
            "Epoch 00081: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5301 - accuracy: 0.8889 - val_loss: 1.2373 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 82/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.8807\n",
            "Epoch 00082: val_loss did not improve from 1.21722\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5495 - accuracy: 0.8807 - val_loss: 1.2694 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 83/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5072 - accuracy: 0.8885\n",
            "Epoch 00083: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5072 - accuracy: 0.8885 - val_loss: 1.2475 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 84/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4995 - accuracy: 0.8946\n",
            "Epoch 00084: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4995 - accuracy: 0.8946 - val_loss: 1.2340 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 85/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5056 - accuracy: 0.8899\n",
            "Epoch 00085: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5056 - accuracy: 0.8899 - val_loss: 1.2263 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 86/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.8994\n",
            "Epoch 00086: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.4783 - accuracy: 0.8994 - val_loss: 1.2189 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
            "Epoch 87/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4704 - accuracy: 0.8990\n",
            "Epoch 00087: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4704 - accuracy: 0.8990 - val_loss: 1.2270 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 88/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4785 - accuracy: 0.8980\n",
            "Epoch 00088: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4785 - accuracy: 0.8980 - val_loss: 1.2494 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 89/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4749 - accuracy: 0.8987\n",
            "Epoch 00089: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4749 - accuracy: 0.8987 - val_loss: 1.2411 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 90/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4780 - accuracy: 0.8960\n",
            "Epoch 00090: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4780 - accuracy: 0.8960 - val_loss: 1.2385 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 91/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4775 - accuracy: 0.8997\n",
            "Epoch 00091: val_loss did not improve from 1.21722\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4775 - accuracy: 0.8997 - val_loss: 1.2455 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 92/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4649 - accuracy: 0.9055\n",
            "Epoch 00092: val_loss improved from 1.21722 to 1.21348, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/092.h5\n",
            "59/59 [==============================] - 122s 2s/step - loss: 1.4649 - accuracy: 0.9055 - val_loss: 1.2135 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 93/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4551 - accuracy: 0.9065\n",
            "Epoch 00093: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4551 - accuracy: 0.9065 - val_loss: 1.2289 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 94/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4631 - accuracy: 0.9007\n",
            "Epoch 00094: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4631 - accuracy: 0.9007 - val_loss: 1.2393 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 95/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4386 - accuracy: 0.9109\n",
            "Epoch 00095: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4386 - accuracy: 0.9109 - val_loss: 1.2172 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 96/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4509 - accuracy: 0.9079\n",
            "Epoch 00096: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4509 - accuracy: 0.9079 - val_loss: 1.2323 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 97/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4434 - accuracy: 0.9075\n",
            "Epoch 00097: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4434 - accuracy: 0.9075 - val_loss: 1.2242 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 98/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4325 - accuracy: 0.9120\n",
            "Epoch 00098: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4325 - accuracy: 0.9120 - val_loss: 1.2360 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 99/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4194 - accuracy: 0.9130\n",
            "Epoch 00099: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4194 - accuracy: 0.9130 - val_loss: 1.2173 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 100/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4334 - accuracy: 0.9126\n",
            "Epoch 00100: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.4334 - accuracy: 0.9126 - val_loss: 1.2272 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 101/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4144 - accuracy: 0.9171\n",
            "Epoch 00101: val_loss did not improve from 1.21348\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4144 - accuracy: 0.9171 - val_loss: 1.2201 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 102/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4222 - accuracy: 0.9174\n",
            "Epoch 00102: val_loss improved from 1.21348 to 1.21308, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-8-20-41-45-personality/102.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.4222 - accuracy: 0.9174 - val_loss: 1.2131 - val_accuracy: 0.9003 - lr: 2.5000e-05\n",
            "Epoch 103/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4236 - accuracy: 0.9140\n",
            "Epoch 00103: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4236 - accuracy: 0.9140 - val_loss: 1.2208 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 104/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.9171\n",
            "Epoch 00104: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4055 - accuracy: 0.9171 - val_loss: 1.2481 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 105/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4107 - accuracy: 0.9143\n",
            "Epoch 00105: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4107 - accuracy: 0.9143 - val_loss: 1.2415 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 106/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4015 - accuracy: 0.9215\n",
            "Epoch 00106: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4015 - accuracy: 0.9215 - val_loss: 1.2198 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 107/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4080 - accuracy: 0.9150\n",
            "Epoch 00107: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4080 - accuracy: 0.9150 - val_loss: 1.2208 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 108/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3999 - accuracy: 0.9228\n",
            "Epoch 00108: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3999 - accuracy: 0.9228 - val_loss: 1.2471 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 109/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3882 - accuracy: 0.9273\n",
            "Epoch 00109: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3882 - accuracy: 0.9273 - val_loss: 1.2239 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 110/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3841 - accuracy: 0.9286\n",
            "Epoch 00110: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3841 - accuracy: 0.9286 - val_loss: 1.2347 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 111/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3896 - accuracy: 0.9222\n",
            "Epoch 00111: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3896 - accuracy: 0.9222 - val_loss: 1.2296 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 112/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3951 - accuracy: 0.9160\n",
            "Epoch 00112: val_loss did not improve from 1.21308\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3951 - accuracy: 0.9160 - val_loss: 1.2293 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 113/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3767 - accuracy: 0.9259\n",
            "Epoch 00113: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3767 - accuracy: 0.9259 - val_loss: 1.2327 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 114/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3555 - accuracy: 0.9341\n",
            "Epoch 00114: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3555 - accuracy: 0.9341 - val_loss: 1.2151 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 115/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3594 - accuracy: 0.9341\n",
            "Epoch 00115: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3594 - accuracy: 0.9341 - val_loss: 1.2338 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 116/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3488 - accuracy: 0.9375\n",
            "Epoch 00116: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3488 - accuracy: 0.9375 - val_loss: 1.2235 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 117/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.9341\n",
            "Epoch 00117: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3596 - accuracy: 0.9341 - val_loss: 1.2248 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 118/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3609 - accuracy: 0.9334\n",
            "Epoch 00118: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.3609 - accuracy: 0.9334 - val_loss: 1.2434 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 119/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3562 - accuracy: 0.9310\n",
            "Epoch 00119: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3562 - accuracy: 0.9310 - val_loss: 1.2315 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 120/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3658 - accuracy: 0.9317\n",
            "Epoch 00120: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3658 - accuracy: 0.9317 - val_loss: 1.2387 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 121/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3618 - accuracy: 0.9317\n",
            "Epoch 00121: val_loss did not improve from 1.21308\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.3618 - accuracy: 0.9317 - val_loss: 1.2261 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 122/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3600 - accuracy: 0.9330\n",
            "Epoch 00122: val_loss did not improve from 1.21308\n",
            "Restoring model weights from the end of the best epoch: 102.\n",
            "\n",
            "Epoch 00122: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3600 - accuracy: 0.9330 - val_loss: 1.2367 - val_accuracy: 0.8969 - lr: 1.2500e-05\n",
            "Epoch 00122: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting...\n",
            "7/7 [==============================] - 24s 2s/step\n",
            "\n",
            "Confusion matrix:\n",
            "[[206  17]\n",
            " [ 15  88]]\n",
            "\n",
            "Evaluating...\n",
            "7/7 [==============================] - 12s 1s/step - loss: 1.1425 - accuracy: 0.9018\n",
            "\n",
            "Per class accuracy:\n",
            "0: 0.9237668161434978\n",
            "1: 0.8543689320388349\n",
            "Average class accuracy: 0.8890678740911664\n",
            "F1 score: [0.92792793 0.84615385]. Avg F1: 0.887040887040887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart()\n",
        "# start_colab()\n",
        "# extract_data()\n",
        "# fold_p2m = create_folds_p2m()\n",
        "# save_folds([fold_p2m])\n",
        "\n",
        "gen_train = Generator_V('Train', batch_size, time_frames)\n",
        "gen_val = Generator_V('Validation', batch_size, time_frames)\n",
        "gen_test = Generator_V('Test', batch_size, time_frames)\n",
        "\n",
        "model, save_dir, epoch = build_model(epoch, print_model=False)\n",
        "\n",
        "callbacks = set_callbacks()\n",
        "fit_model(list(len(gen_train.labels) / np.sum(gen_train.labels, axis=0)), epoch)\n",
        "gen_test = predict()\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUlcPPbGEZb5",
        "outputId": "c6cc5e26-97cc-4f3a-b2c2-5e2e067bb0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "Building model...\n",
            "Train weights: {0: 2.5943563, 1: 1.6272124}\n",
            "Epoch 1/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 6.9255 - accuracy: 0.5364\n",
            "Epoch 00001: val_loss improved from inf to 1.36262, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/001.h5\n",
            "59/59 [==============================] - 160s 2s/step - loss: 6.9255 - accuracy: 0.5364 - val_loss: 1.3626 - val_accuracy: 0.7938 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2724 - accuracy: 0.5700\n",
            "Epoch 00002: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.2724 - accuracy: 0.5700 - val_loss: 1.4666 - val_accuracy: 0.7457 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1439 - accuracy: 0.6169\n",
            "Epoch 00003: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1439 - accuracy: 0.6169 - val_loss: 1.4399 - val_accuracy: 0.7698 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1382 - accuracy: 0.6268\n",
            "Epoch 00004: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1382 - accuracy: 0.6268 - val_loss: 1.4666 - val_accuracy: 0.7457 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1373 - accuracy: 0.6509\n",
            "Epoch 00005: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.1373 - accuracy: 0.6509 - val_loss: 1.4726 - val_accuracy: 0.7148 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1263 - accuracy: 0.6502\n",
            "Epoch 00006: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.1263 - accuracy: 0.6502 - val_loss: 1.4839 - val_accuracy: 0.7388 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0794 - accuracy: 0.6832\n",
            "Epoch 00007: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0794 - accuracy: 0.6832 - val_loss: 1.4437 - val_accuracy: 0.7766 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0564 - accuracy: 0.6961\n",
            "Epoch 00008: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0564 - accuracy: 0.6961 - val_loss: 1.4218 - val_accuracy: 0.7869 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0291 - accuracy: 0.7155\n",
            "Epoch 00009: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0291 - accuracy: 0.7155 - val_loss: 1.4471 - val_accuracy: 0.8247 - lr: 1.0000e-04\n",
            "Epoch 10/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0170 - accuracy: 0.7271\n",
            "Epoch 00010: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 2.0170 - accuracy: 0.7271 - val_loss: 1.3851 - val_accuracy: 0.7973 - lr: 1.0000e-04\n",
            "Epoch 11/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0040 - accuracy: 0.7257\n",
            "Epoch 00011: val_loss did not improve from 1.36262\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0040 - accuracy: 0.7257 - val_loss: 1.3657 - val_accuracy: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 12/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9895 - accuracy: 0.7311\n",
            "Epoch 00012: val_loss did not improve from 1.36262\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9895 - accuracy: 0.7311 - val_loss: 1.3637 - val_accuracy: 0.8488 - lr: 5.0000e-05\n",
            "Epoch 13/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9736 - accuracy: 0.7546\n",
            "Epoch 00013: val_loss improved from 1.36262 to 1.35915, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/013.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.9736 - accuracy: 0.7546 - val_loss: 1.3592 - val_accuracy: 0.8351 - lr: 5.0000e-05\n",
            "Epoch 14/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9462 - accuracy: 0.7624\n",
            "Epoch 00014: val_loss improved from 1.35915 to 1.35026, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/014.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.9462 - accuracy: 0.7624 - val_loss: 1.3503 - val_accuracy: 0.8419 - lr: 5.0000e-05\n",
            "Epoch 15/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9291 - accuracy: 0.7648\n",
            "Epoch 00015: val_loss did not improve from 1.35026\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9291 - accuracy: 0.7648 - val_loss: 1.3522 - val_accuracy: 0.8488 - lr: 5.0000e-05\n",
            "Epoch 16/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9432 - accuracy: 0.7672\n",
            "Epoch 00016: val_loss improved from 1.35026 to 1.34467, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/016.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.9432 - accuracy: 0.7672 - val_loss: 1.3447 - val_accuracy: 0.8488 - lr: 5.0000e-05\n",
            "Epoch 17/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9191 - accuracy: 0.7797\n",
            "Epoch 00017: val_loss did not improve from 1.34467\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.9191 - accuracy: 0.7797 - val_loss: 1.3527 - val_accuracy: 0.8522 - lr: 5.0000e-05\n",
            "Epoch 18/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8787 - accuracy: 0.7791\n",
            "Epoch 00018: val_loss did not improve from 1.34467\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8787 - accuracy: 0.7791 - val_loss: 1.3452 - val_accuracy: 0.8419 - lr: 5.0000e-05\n",
            "Epoch 19/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9025 - accuracy: 0.7828\n",
            "Epoch 00019: val_loss improved from 1.34467 to 1.32112, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/019.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.9025 - accuracy: 0.7828 - val_loss: 1.3211 - val_accuracy: 0.8729 - lr: 5.0000e-05\n",
            "Epoch 20/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8794 - accuracy: 0.7944\n",
            "Epoch 00020: val_loss did not improve from 1.32112\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.8794 - accuracy: 0.7944 - val_loss: 1.3324 - val_accuracy: 0.8625 - lr: 5.0000e-05\n",
            "Epoch 21/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8594 - accuracy: 0.8012\n",
            "Epoch 00021: val_loss did not improve from 1.32112\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.8594 - accuracy: 0.8012 - val_loss: 1.3446 - val_accuracy: 0.8454 - lr: 5.0000e-05\n",
            "Epoch 22/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8623 - accuracy: 0.8008\n",
            "Epoch 00022: val_loss did not improve from 1.32112\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.8623 - accuracy: 0.8008 - val_loss: 1.3288 - val_accuracy: 0.8729 - lr: 5.0000e-05\n",
            "Epoch 23/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8345 - accuracy: 0.8100\n",
            "Epoch 00023: val_loss did not improve from 1.32112\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8345 - accuracy: 0.8100 - val_loss: 1.3535 - val_accuracy: 0.8522 - lr: 5.0000e-05\n",
            "Epoch 24/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8426 - accuracy: 0.8049\n",
            "Epoch 00024: val_loss improved from 1.32112 to 1.29759, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/024.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.8426 - accuracy: 0.8049 - val_loss: 1.2976 - val_accuracy: 0.8694 - lr: 5.0000e-05\n",
            "Epoch 25/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8451 - accuracy: 0.7998\n",
            "Epoch 00025: val_loss did not improve from 1.29759\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.8451 - accuracy: 0.7998 - val_loss: 1.3055 - val_accuracy: 0.8625 - lr: 5.0000e-05\n",
            "Epoch 26/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8160 - accuracy: 0.8188\n",
            "Epoch 00026: val_loss did not improve from 1.29759\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.8160 - accuracy: 0.8188 - val_loss: 1.3061 - val_accuracy: 0.8694 - lr: 5.0000e-05\n",
            "Epoch 27/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8086 - accuracy: 0.8141\n",
            "Epoch 00027: val_loss improved from 1.29759 to 1.25991, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/027.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.8086 - accuracy: 0.8141 - val_loss: 1.2599 - val_accuracy: 0.8797 - lr: 5.0000e-05\n",
            "Epoch 28/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7877 - accuracy: 0.8151\n",
            "Epoch 00028: val_loss did not improve from 1.25991\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7877 - accuracy: 0.8151 - val_loss: 1.2684 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 29/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7769 - accuracy: 0.8290\n",
            "Epoch 00029: val_loss did not improve from 1.25991\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.7769 - accuracy: 0.8290 - val_loss: 1.3023 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 30/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7839 - accuracy: 0.8161\n",
            "Epoch 00030: val_loss did not improve from 1.25991\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7839 - accuracy: 0.8161 - val_loss: 1.2693 - val_accuracy: 0.8763 - lr: 5.0000e-05\n",
            "Epoch 31/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7771 - accuracy: 0.8243\n",
            "Epoch 00031: val_loss did not improve from 1.25991\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.7771 - accuracy: 0.8243 - val_loss: 1.2733 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 32/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7704 - accuracy: 0.8324\n",
            "Epoch 00032: val_loss improved from 1.25991 to 1.25284, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/032.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.7704 - accuracy: 0.8324 - val_loss: 1.2528 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 33/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7565 - accuracy: 0.8300\n",
            "Epoch 00033: val_loss did not improve from 1.25284\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7565 - accuracy: 0.8300 - val_loss: 1.2596 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 34/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7485 - accuracy: 0.8338\n",
            "Epoch 00034: val_loss improved from 1.25284 to 1.24686, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/034.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.7485 - accuracy: 0.8338 - val_loss: 1.2469 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 35/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7577 - accuracy: 0.8253\n",
            "Epoch 00035: val_loss did not improve from 1.24686\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7577 - accuracy: 0.8253 - val_loss: 1.2545 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 36/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7430 - accuracy: 0.8406\n",
            "Epoch 00036: val_loss did not improve from 1.24686\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7430 - accuracy: 0.8406 - val_loss: 1.2492 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 37/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7124 - accuracy: 0.8382\n",
            "Epoch 00037: val_loss did not improve from 1.24686\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7124 - accuracy: 0.8382 - val_loss: 1.2479 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 38/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7256 - accuracy: 0.8314\n",
            "Epoch 00038: val_loss improved from 1.24686 to 1.24569, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/038.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.7256 - accuracy: 0.8314 - val_loss: 1.2457 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 39/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7091 - accuracy: 0.8402\n",
            "Epoch 00039: val_loss improved from 1.24569 to 1.23320, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/039.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.7091 - accuracy: 0.8402 - val_loss: 1.2332 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 40/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7108 - accuracy: 0.8433\n",
            "Epoch 00040: val_loss did not improve from 1.23320\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.7108 - accuracy: 0.8433 - val_loss: 1.2516 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 41/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7236 - accuracy: 0.8375\n",
            "Epoch 00041: val_loss did not improve from 1.23320\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.7236 - accuracy: 0.8375 - val_loss: 1.2580 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 42/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6931 - accuracy: 0.8464\n",
            "Epoch 00042: val_loss did not improve from 1.23320\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6931 - accuracy: 0.8464 - val_loss: 1.2335 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 43/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6684 - accuracy: 0.8440\n",
            "Epoch 00043: val_loss improved from 1.23320 to 1.22479, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/043.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.6684 - accuracy: 0.8440 - val_loss: 1.2248 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 44/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6678 - accuracy: 0.8545\n",
            "Epoch 00044: val_loss improved from 1.22479 to 1.19877, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/044.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.6678 - accuracy: 0.8545 - val_loss: 1.1988 - val_accuracy: 0.9003 - lr: 5.0000e-05\n",
            "Epoch 45/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6486 - accuracy: 0.8464\n",
            "Epoch 00045: val_loss did not improve from 1.19877\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6486 - accuracy: 0.8464 - val_loss: 1.2359 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 46/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6614 - accuracy: 0.8528\n",
            "Epoch 00046: val_loss did not improve from 1.19877\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6614 - accuracy: 0.8528 - val_loss: 1.2555 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 47/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6432 - accuracy: 0.8566\n",
            "Epoch 00047: val_loss did not improve from 1.19877\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6432 - accuracy: 0.8566 - val_loss: 1.2109 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 48/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6312 - accuracy: 0.8583\n",
            "Epoch 00048: val_loss improved from 1.19877 to 1.19873, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/048.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.6312 - accuracy: 0.8583 - val_loss: 1.1987 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 49/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6353 - accuracy: 0.8596\n",
            "Epoch 00049: val_loss did not improve from 1.19873\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.6353 - accuracy: 0.8596 - val_loss: 1.2178 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 50/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6353 - accuracy: 0.8593\n",
            "Epoch 00050: val_loss did not improve from 1.19873\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.6353 - accuracy: 0.8593 - val_loss: 1.2052 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 51/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5959 - accuracy: 0.8569\n",
            "Epoch 00051: val_loss did not improve from 1.19873\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5959 - accuracy: 0.8569 - val_loss: 1.2305 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 52/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5998 - accuracy: 0.8651\n",
            "Epoch 00052: val_loss did not improve from 1.19873\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5998 - accuracy: 0.8651 - val_loss: 1.2001 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 53/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5801 - accuracy: 0.8712\n",
            "Epoch 00053: val_loss did not improve from 1.19873\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5801 - accuracy: 0.8712 - val_loss: 1.2194 - val_accuracy: 0.8866 - lr: 5.0000e-05\n",
            "Epoch 54/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6168 - accuracy: 0.8637\n",
            "Epoch 00054: val_loss improved from 1.19873 to 1.19409, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/054.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.6168 - accuracy: 0.8637 - val_loss: 1.1941 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 55/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.8715\n",
            "Epoch 00055: val_loss did not improve from 1.19409\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5848 - accuracy: 0.8715 - val_loss: 1.2128 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 56/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5386 - accuracy: 0.8742\n",
            "Epoch 00056: val_loss improved from 1.19409 to 1.18558, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/056.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.5386 - accuracy: 0.8742 - val_loss: 1.1856 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 57/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5680 - accuracy: 0.8749\n",
            "Epoch 00057: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5680 - accuracy: 0.8749 - val_loss: 1.1994 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 58/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.8736\n",
            "Epoch 00058: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5732 - accuracy: 0.8736 - val_loss: 1.2100 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 59/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5528 - accuracy: 0.8756\n",
            "Epoch 00059: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5528 - accuracy: 0.8756 - val_loss: 1.2296 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 60/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5607 - accuracy: 0.8739\n",
            "Epoch 00060: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5607 - accuracy: 0.8739 - val_loss: 1.1979 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 61/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5195 - accuracy: 0.8783\n",
            "Epoch 00061: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5195 - accuracy: 0.8783 - val_loss: 1.2032 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 62/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5389 - accuracy: 0.8746\n",
            "Epoch 00062: val_loss did not improve from 1.18558\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.5389 - accuracy: 0.8746 - val_loss: 1.2468 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 63/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 0.8841\n",
            "Epoch 00063: val_loss improved from 1.18558 to 1.18258, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/063.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.5300 - accuracy: 0.8841 - val_loss: 1.1826 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 64/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5133 - accuracy: 0.8841\n",
            "Epoch 00064: val_loss did not improve from 1.18258\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5133 - accuracy: 0.8841 - val_loss: 1.2253 - val_accuracy: 0.8832 - lr: 5.0000e-05\n",
            "Epoch 65/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5120 - accuracy: 0.8875\n",
            "Epoch 00065: val_loss did not improve from 1.18258\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5120 - accuracy: 0.8875 - val_loss: 1.1926 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 66/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5153 - accuracy: 0.8814\n",
            "Epoch 00066: val_loss improved from 1.18258 to 1.18055, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/066.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.5153 - accuracy: 0.8814 - val_loss: 1.1805 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 67/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4974 - accuracy: 0.8851\n",
            "Epoch 00067: val_loss did not improve from 1.18055\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4974 - accuracy: 0.8851 - val_loss: 1.1865 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 68/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5020 - accuracy: 0.8868\n",
            "Epoch 00068: val_loss did not improve from 1.18055\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.5020 - accuracy: 0.8868 - val_loss: 1.1981 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 69/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.8878\n",
            "Epoch 00069: val_loss improved from 1.18055 to 1.17036, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/069.h5\n",
            "59/59 [==============================] - 120s 2s/step - loss: 1.4646 - accuracy: 0.8878 - val_loss: 1.1704 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 70/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4690 - accuracy: 0.8923\n",
            "Epoch 00070: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4690 - accuracy: 0.8923 - val_loss: 1.1937 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 71/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.8865\n",
            "Epoch 00071: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4696 - accuracy: 0.8865 - val_loss: 1.2057 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 72/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4539 - accuracy: 0.8929\n",
            "Epoch 00072: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4539 - accuracy: 0.8929 - val_loss: 1.1984 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 73/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.8916\n",
            "Epoch 00073: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4659 - accuracy: 0.8916 - val_loss: 1.1810 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 74/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4635 - accuracy: 0.8868\n",
            "Epoch 00074: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4635 - accuracy: 0.8868 - val_loss: 1.2053 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 75/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4552 - accuracy: 0.8909\n",
            "Epoch 00075: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4552 - accuracy: 0.8909 - val_loss: 1.2355 - val_accuracy: 0.8660 - lr: 5.0000e-05\n",
            "Epoch 76/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4152 - accuracy: 0.9024\n",
            "Epoch 00076: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.4152 - accuracy: 0.9024 - val_loss: 1.2023 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 77/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4352 - accuracy: 0.9004\n",
            "Epoch 00077: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4352 - accuracy: 0.9004 - val_loss: 1.1856 - val_accuracy: 0.8969 - lr: 5.0000e-05\n",
            "Epoch 78/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4172 - accuracy: 0.8953\n",
            "Epoch 00078: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4172 - accuracy: 0.8953 - val_loss: 1.1746 - val_accuracy: 0.8900 - lr: 5.0000e-05\n",
            "Epoch 79/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.4142 - accuracy: 0.9018\n",
            "Epoch 00079: val_loss did not improve from 1.17036\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.4142 - accuracy: 0.9018 - val_loss: 1.1861 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
            "Epoch 80/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3826 - accuracy: 0.9089\n",
            "Epoch 00080: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3826 - accuracy: 0.9089 - val_loss: 1.1915 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
            "Epoch 81/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3662 - accuracy: 0.9126\n",
            "Epoch 00081: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3662 - accuracy: 0.9126 - val_loss: 1.2021 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 82/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3679 - accuracy: 0.9177\n",
            "Epoch 00082: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3679 - accuracy: 0.9177 - val_loss: 1.1866 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
            "Epoch 83/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3470 - accuracy: 0.9154\n",
            "Epoch 00083: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3470 - accuracy: 0.9154 - val_loss: 1.1919 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 84/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3712 - accuracy: 0.9167\n",
            "Epoch 00084: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3712 - accuracy: 0.9167 - val_loss: 1.1894 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 85/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3415 - accuracy: 0.9177\n",
            "Epoch 00085: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3415 - accuracy: 0.9177 - val_loss: 1.1947 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 86/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3514 - accuracy: 0.9130\n",
            "Epoch 00086: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3514 - accuracy: 0.9130 - val_loss: 1.1913 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 87/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3577 - accuracy: 0.9191\n",
            "Epoch 00087: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3577 - accuracy: 0.9191 - val_loss: 1.1907 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 88/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3385 - accuracy: 0.9201\n",
            "Epoch 00088: val_loss did not improve from 1.17036\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3385 - accuracy: 0.9201 - val_loss: 1.1805 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 89/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3204 - accuracy: 0.9252\n",
            "Epoch 00089: val_loss improved from 1.17036 to 1.16217, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/089.h5\n",
            "59/59 [==============================] - 121s 2s/step - loss: 1.3204 - accuracy: 0.9252 - val_loss: 1.1622 - val_accuracy: 0.8969 - lr: 2.5000e-05\n",
            "Epoch 90/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3241 - accuracy: 0.9279\n",
            "Epoch 00090: val_loss did not improve from 1.16217\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3241 - accuracy: 0.9279 - val_loss: 1.1720 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 91/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3290 - accuracy: 0.9225\n",
            "Epoch 00091: val_loss did not improve from 1.16217\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3290 - accuracy: 0.9225 - val_loss: 1.1737 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 92/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3243 - accuracy: 0.9252\n",
            "Epoch 00092: val_loss did not improve from 1.16217\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3243 - accuracy: 0.9252 - val_loss: 1.1911 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 93/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.9242\n",
            "Epoch 00093: val_loss did not improve from 1.16217\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.3256 - accuracy: 0.9242 - val_loss: 1.2103 - val_accuracy: 0.8729 - lr: 2.5000e-05\n",
            "Epoch 94/1000\n",
            "38/59 [==================>...........] - ETA: 37s - loss: 1.3052 - accuracy: 0.9289"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart()\n",
        "# start_colab()\n",
        "# extract_data()\n",
        "# fold_p2m = create_folds_p2m()\n",
        "# save_folds([fold_p2m])\n",
        "\n",
        "# gen_train = Generator_V('Train', batch_size, time_frames)\n",
        "# gen_val = Generator_V('Validation', batch_size, time_frames)\n",
        "# gen_test = Generator_V('Test', batch_size, time_frames)\n",
        "\n",
        "model, save_dir, epoch = build_model(epoch, print_model=False)\n",
        "\n",
        "callbacks = set_callbacks()\n",
        "fit_model(list(len(gen_train.labels) / np.sum(gen_train.labels, axis=0)), epoch)\n",
        "gen_test = predict()\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tqz6eWz9xj3a",
        "outputId": "fa724a8e-c2d7-4a97-f983-1f6224a3d181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n",
            "Loading model from drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/089.h5.\n",
            "Train weights: {0: 2.5943563, 1: 1.6272124}\n",
            "Epoch 90/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3448 - accuracy: 0.9184\n",
            "Epoch 00090: val_loss improved from inf to 1.20133, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/090.h5\n",
            "59/59 [==============================] - 162s 2s/step - loss: 1.3448 - accuracy: 0.9184 - val_loss: 1.2013 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 91/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3202 - accuracy: 0.9211\n",
            "Epoch 00091: val_loss improved from 1.20133 to 1.17368, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/091.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.3202 - accuracy: 0.9211 - val_loss: 1.1737 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 92/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3352 - accuracy: 0.9249\n",
            "Epoch 00092: val_loss did not improve from 1.17368\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3352 - accuracy: 0.9249 - val_loss: 1.2000 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 93/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3340 - accuracy: 0.9157\n",
            "Epoch 00093: val_loss did not improve from 1.17368\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3340 - accuracy: 0.9157 - val_loss: 1.1880 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 94/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3233 - accuracy: 0.9222\n",
            "Epoch 00094: val_loss did not improve from 1.17368\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3233 - accuracy: 0.9222 - val_loss: 1.1740 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
            "Epoch 95/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3037 - accuracy: 0.9344\n",
            "Epoch 00095: val_loss did not improve from 1.17368\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3037 - accuracy: 0.9344 - val_loss: 1.1826 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 96/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2888 - accuracy: 0.9310\n",
            "Epoch 00096: val_loss did not improve from 1.17368\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2888 - accuracy: 0.9310 - val_loss: 1.1803 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 97/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2937 - accuracy: 0.9320\n",
            "Epoch 00097: val_loss improved from 1.17368 to 1.17145, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/097.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.2937 - accuracy: 0.9320 - val_loss: 1.1714 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 98/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3011 - accuracy: 0.9310\n",
            "Epoch 00098: val_loss did not improve from 1.17145\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3011 - accuracy: 0.9310 - val_loss: 1.1976 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 99/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3064 - accuracy: 0.9330\n",
            "Epoch 00099: val_loss did not improve from 1.17145\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.3064 - accuracy: 0.9330 - val_loss: 1.1778 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 100/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.3019 - accuracy: 0.9266\n",
            "Epoch 00100: val_loss did not improve from 1.17145\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.3019 - accuracy: 0.9266 - val_loss: 1.2035 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 101/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2667 - accuracy: 0.9341\n",
            "Epoch 00101: val_loss improved from 1.17145 to 1.17026, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-2-44-8-personality/101.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.2667 - accuracy: 0.9341 - val_loss: 1.1703 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 102/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2916 - accuracy: 0.9358\n",
            "Epoch 00102: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2916 - accuracy: 0.9358 - val_loss: 1.1936 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 103/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2948 - accuracy: 0.9347\n",
            "Epoch 00103: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2948 - accuracy: 0.9347 - val_loss: 1.1761 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 104/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2920 - accuracy: 0.9320\n",
            "Epoch 00104: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2920 - accuracy: 0.9320 - val_loss: 1.1869 - val_accuracy: 0.8797 - lr: 2.5000e-05\n",
            "Epoch 105/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2755 - accuracy: 0.9344\n",
            "Epoch 00105: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2755 - accuracy: 0.9344 - val_loss: 1.1855 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 106/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2771 - accuracy: 0.9313\n",
            "Epoch 00106: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2771 - accuracy: 0.9313 - val_loss: 1.1926 - val_accuracy: 0.8797 - lr: 2.5000e-05\n",
            "Epoch 107/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.9371\n",
            "Epoch 00107: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2684 - accuracy: 0.9371 - val_loss: 1.1840 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 108/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2469 - accuracy: 0.9463\n",
            "Epoch 00108: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2469 - accuracy: 0.9463 - val_loss: 1.2053 - val_accuracy: 0.8763 - lr: 2.5000e-05\n",
            "Epoch 109/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2517 - accuracy: 0.9378\n",
            "Epoch 00109: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2517 - accuracy: 0.9378 - val_loss: 1.1771 - val_accuracy: 0.8866 - lr: 2.5000e-05\n",
            "Epoch 110/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2511 - accuracy: 0.9409\n",
            "Epoch 00110: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.2511 - accuracy: 0.9409 - val_loss: 1.1726 - val_accuracy: 0.8900 - lr: 2.5000e-05\n",
            "Epoch 111/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2565 - accuracy: 0.9415\n",
            "Epoch 00111: val_loss did not improve from 1.17026\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2565 - accuracy: 0.9415 - val_loss: 1.1919 - val_accuracy: 0.8832 - lr: 2.5000e-05\n",
            "Epoch 112/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2278 - accuracy: 0.9500\n",
            "Epoch 00112: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2278 - accuracy: 0.9500 - val_loss: 1.1899 - val_accuracy: 0.8797 - lr: 1.2500e-05\n",
            "Epoch 113/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2483 - accuracy: 0.9432\n",
            "Epoch 00113: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2483 - accuracy: 0.9432 - val_loss: 1.1898 - val_accuracy: 0.8797 - lr: 1.2500e-05\n",
            "Epoch 114/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2449 - accuracy: 0.9443\n",
            "Epoch 00114: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2449 - accuracy: 0.9443 - val_loss: 1.1922 - val_accuracy: 0.8832 - lr: 1.2500e-05\n",
            "Epoch 115/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2450 - accuracy: 0.9443\n",
            "Epoch 00115: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2450 - accuracy: 0.9443 - val_loss: 1.1935 - val_accuracy: 0.8797 - lr: 1.2500e-05\n",
            "Epoch 116/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.9439\n",
            "Epoch 00116: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2350 - accuracy: 0.9439 - val_loss: 1.1857 - val_accuracy: 0.8866 - lr: 1.2500e-05\n",
            "Epoch 117/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2321 - accuracy: 0.9500\n",
            "Epoch 00117: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2321 - accuracy: 0.9500 - val_loss: 1.1965 - val_accuracy: 0.8832 - lr: 1.2500e-05\n",
            "Epoch 118/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2206 - accuracy: 0.9538\n",
            "Epoch 00118: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2206 - accuracy: 0.9538 - val_loss: 1.2053 - val_accuracy: 0.8763 - lr: 1.2500e-05\n",
            "Epoch 119/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2202 - accuracy: 0.9490\n",
            "Epoch 00119: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2202 - accuracy: 0.9490 - val_loss: 1.2020 - val_accuracy: 0.8763 - lr: 1.2500e-05\n",
            "Epoch 120/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2317 - accuracy: 0.9477\n",
            "Epoch 00120: val_loss did not improve from 1.17026\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.2317 - accuracy: 0.9477 - val_loss: 1.1944 - val_accuracy: 0.8729 - lr: 1.2500e-05\n",
            "Epoch 121/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.2243 - accuracy: 0.9504\n",
            "Epoch 00121: val_loss did not improve from 1.17026\n",
            "Restoring model weights from the end of the best epoch: 101.\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.2243 - accuracy: 0.9504 - val_loss: 1.2006 - val_accuracy: 0.8763 - lr: 1.2500e-05\n",
            "Epoch 00121: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e+hCdKk49J1UenFiKD+BAuKqCAoIi4uWLCiglhAXHXBgoqKBVFUZHHdRcS6iBVBVBQJ0gSkiChFqlSpSc7vjzORMUwyk8wkk5mcz/PMw8wt7z03N5y5ee9bRFVxzjmXvIrFOwDnnHP5yxO9c84lOU/0zjmX5DzRO+dckvNE75xzSa5EvAPIqmrVqlq/fv14h+Gccwll7ty5W1S1Wqh1hS7R169fn9TU1HiH4ZxzCUVEfs5unVfdOOdckvNE75xzSc4TvXPOJblCV0cfysGDB1m7di379u2LdyiFUunSpalduzYlS5aMdyjOuUIoIRL92rVrKV++PPXr10dE4h1OoaKqbN26lbVr19KgQYN4h+OcK4QSoupm3759VKlSxZN8CCJClSpV/K8d51y2EiLRA57kc+A/G+dcThIm0TvnXEHYuxfGjoVt2+IdSex4onfOuYCdO+G88+C66+Cii+DAgXhHFBue6J1zDti8Gc48E776yhL9zJlw/fWQDHMzeaLPhYsuuogTTzyRJk2aMHbsWAA+/PBDWrduTYsWLTjrrLMA2L17N1deeSXNmjWjefPmvPnmm/EM2zkXxpo18H//B4sXw7vvwvPPw333wSuvwGOPxTu66CVE88pgAwbA/PmxLbNlSxg1Kvx248aNo3Llyuzdu5eTTjqJrl270q9fP2bOnEmDBg347bffABg+fDgVK1Zk0aJFAGxLpso+55LM8uVw9tmwYwd8/LElfLBEv2wZDB4MDRtCt27xjTMaCZfo4+npp5/m7bffBmDNmjWMHTuW008//Y/265UrVwbg008/ZeLEiX/sV6lSpYIP1jkX1rx5cO659n7GDGjV6tA6ERg3Dlavht694YsvoHXreEQZvYRL9JHceeeHGTNm8Omnn/L1119z5JFH0qFDB1q2bMkPP/wQn4Ccc1H54gu44AI46ij45BM47rjDtylTBt55B9q0gQsvhG+/hVq1Cj7WaEVURy8inURkmYisFJHBIdbXE5FpIrJQRGaISO2gdekiMj/wei+WwRekHTt2UKlSJY488kh++OEHvvnmG/bt28fMmTP56aefAP6ouunYsSOjR4/+Y1+vunGucJk6Fc45B/7yF/jyy9BJPlONGjBlirXI6dIFfv+94OKMlbCJXkSKA6OB84DGQC8RaZxls5HABFVtDgwDHg5at1dVWwZeXWIUd4Hr1KkTaWlpNGrUiMGDB9O2bVuqVavG2LFj6d69Oy1atKBnz54A3HPPPWzbto2mTZvSokULpk+fHufonXOZ/vtf6NoVmjSxljV16oTfp1kzmDjRng9ecQVkZMQ+rk2bYMGC2JcL2FgpOb2AdsBHQZ+HAEOybLMYqBN4L8DOoHW7wx0j+HXiiSdqVkuWLDlsmfsz/xm5/PbZZ6q7d8c7iuiMGaMqotq+veqOHbnff9QoVVAdPDi2cb3xhmrVqqqNG6ump+etDCBVs8mrkVTd1ALWBH1eG1gWbAHQPfC+G1BeRKoEPpcWkVQR+UZELgp1ABG5NrBN6ubNmyMIyTlXkGbNsjbmt94a70jy7quv4MYb4fzz4YMPoEKF3Jdxyy1www0wYgSMHx99TFu3Qq9e0KMH1K8Pb7wBxfKh0XusirwdaC8i84D2wDogPbCunqqmAJcDo0Tk2Kw7q+pYVU1R1ZRq1UJOeeici6OHA5WxL79sDyQTzd69cNVVUK+eVd2UKZO3ckTgqaegY0e49lr4/PO8xzRlCjRtCpMnw/Dh9mXaOGuleIxEkujXAcG1WLUDy/6gqutVtbuqtgKGBpZtD/y7LvDvKmAG0ArnXMJYtMiS0qBBULMm9O+fP3XU+en++629/EsvQbly0ZVVsiRMmgTHHmt1/YMG2ZdfpD1od+yAK6+0VjzVq8OcOXDPPVZufokk0c8BGopIAxEpBVwG/Kn1jIhUFZHMsoYA4wLLK4nIEZnbAKcCS2IVvHMu/40YAWXLwt13Wy/ROXNiU21RUObMgZEjoV8/CHRej9pRR1n1T/v28OyzcPLJcMwxcNddMHdu9kn/44/tLv7VV2HoUIutZcvYxJSj7Crvg19AZ2A58CMwNLBsGNAl8P4SYEVgm5eAIwLLTwEWYXX4i4Crwx3LH8bmjf+MXH748UfVYsVUBw2yzxkZqqeeqlqtmuq2bfGNLRL79qk2aaJaq5bq9u35c4xt21THj1ft3Fm1RAl7WHvssapDhqjOn28/s507Va+7ztadcILq7Nmxj4McHsZG3BqmoF6e6PPGf0YuP1x/vWqpUqrr1h1a9t131nLlllviF1ek7r3XstyUKQVzvK1bVV96SfWcc1SLF7djH3+8av369jMbNEh1z578OXZOid4HNXPOhbRhgw3q1aePdSzK1KqVjeo4erTV3xdW8+fDQw9Zu/fzzy+YY1auDFdfDR99BL/+Ci+8YD1pq1a1NvsjR+b9QXA0PNHnk3LRPvFxLs6efBIOHoQ77zx83fDhULEi3Hxz4RzG9+BBa2VTpUr8hk2pVs1a5kybZnXxp50WnzjAE71zhYYq/PhjvKMw27fDmDHWvvuvfz18fZUq8OCD1rxw0qSCjy+cxx6zAcvGjLG77KIu4QY1i9c4xYMHD6ZOnTrcdNNNANx///2UKFGC6dOns23bNg4ePMgDDzxA165dwx5u9+7ddO3aNeR+EyZMYOTIkYgIzZs359VXX2Xjxo1cf/31rFq1CoAxY8ZwyimnRHnSrrB5/nm46SZrT922bXxjGT0adu2yIXqz06+fTbk3aJBVjRSWP2KXLIF//hMuvTSxhxaOJdFC9ndXSkqKpqam/mnZ0qVLadSokX2IU6KfN28eAwYM4PNAD4nGjRvz0UcfUbFiRSpUqMCWLVto27YtK1asQEQoV64cu3fvDllWWloae/bsOWy/JUuW0K1bN2bNmkXVqlX57bffqFy5Mj179qRdu3YMGDCA9PR0du/eTcWKFf9U5p9+Ri7hZGTA8cfDypU2cNa778Yvlj17rGPRSSfZ4F85mTULTj0Vhgyx+vB4S0+3eFautIRfvXq8Iyo4IjJXrXPqYRLvjj5OFW6tWrVi06ZNrF+/ns2bN1OpUiVq1qzJwIEDmTlzJsWKFWPdunVs3LiRmjVr5liWqnL33Xcftt9nn31Gjx49qFq1KnBofPvPPvuMCRMmAFC8ePHDkrxLfFOnWnI66SR47z34/ntrbx0PL78MW7ZY8g7nlFPsYefIkdYJqGHD/I8vJ089BbNnw3/+U7SSfDheR58LPXr0YPLkybz++uv07NmT1157jc2bNzN37lzmz59PjRo12LdvX9hy8rqfS16jRkHt2vC//1nnpBEj4hPHwYOWtE899dBMS+E88giULm3j4MSzgmDFCuuE1KULXHZZ/OIojBLvjj6OevbsSb9+/diyZQuff/45kyZNonr16pQsWZLp06fz888/R1TOjh07Qu535pln0q1bN2677TaqVKnyR9XNWWedxZgxY3KsunGJa9Eia5kxYoSNfX7ddXZnOnw4BCYvKzD/+Q/88gs891zk+xx9tE27d/vtNlTChReG32fTJpufNZIvhiOOsLvzatWspY/I4dtkZFizxtKl7QFsqG2KtOwa2MfrVdg7TDVt2lQ7dOigqqqbN2/Wtm3batOmTbVv3756wgkn6E8//aSqqmXLls22jJz2Gz9+vDZp0kSbN2+uffr0UVXVDRs2aJcuXbRp06baokULnTVr1mFlFqafkcudq65SLVPGOtuoqq5dq1qypOoNNxRsHOnp1muzeXPrzZkb+/fbvscco7p37+Hrt2xRffNN1f79raeqpfjcv0qWtF6uLVtap6TevVUHDlTt29fWv/JKTH4UCYkcOkwl3sNYF5L/jBLTpk1Qt67Vb48Zc2h5v342Hsrq1TaQWEF46y24+GIb3TEvVR+ffGKzNj3wgLUemjkTpk+318KFlqqPPNLak59xhj2PiGQgr717YfNm+1lt2hT6/e+/W+xvvFF07+aT62Gsc0nkhRdg/34b5zzYnXfaxNSjRhVMfb2qDUV87LFwySV5K6NjR+je3apx7r3XqlNKl7YHtsOGHUrupUrFNnawL4PSpYtukg/HE30+WrRoEVdcccWflh1xxBHMnj07ThG5wmT/fqsL79QJsv4x1rChJdznnrO27Ecdlb+xTJsGqan2xVMiiqwwapRNnNGkiSX2k0+2BJzf4jGsQCJJmESvqkiCfV03a9aM+bFu8x9CYat+c5GZNMnGkxkwIPT6wYNtm+eesyGC89PDD9tD1T59oiunTh2rPnGFS0I0ryxdujRbt271hBaCqrJ161ZKF8Rtk4sZVRtLplEjq9cOpVUru9sfNco6MeWXb7+Fzz6D226zFi4u+STEHX3t2rVZu3YtPp9saKVLl6Z27drxDsPlwpdf2lgszz+fc73ykCE2ucW4cTazU6xs327NG7//3squVMmadbrklBCtbpxLNhdfDDNmwJo11hIlO6rWcWnNGus5m9vp5nbutKEAFi8+lNgXL4b16w9tU7YsPPGEjbToElfUrW5EpBPwFFAceElVR2RZXw+bPrAa8BvQW1XXBq2vgE0h+I6qxvC+xLnE89NP8M47Nu1cTkke7G5/yBC44ALrzBRpHfrGjdC3L3z44aFlZcpYVdFZZ9nwCk2a2KtuXXuA6pJX2EQvIsWB0UBHYC0wR0TeU9XguV9HAhNU9V8icibwMBDc3GQ4MDN2YTuXuJ55xhLrjTdGtn3nztC8uQ01cMUV4ZPyF19Az56wbZtNOp2SYom9fn0oXjzq8F0CiuR7vA2wUlVXqeoBYCKQdSzexsBngffTg9eLyIlADeDj6MN1LrHt3AkvvWTjvEf6WEXEWuAsXZrzqJYZGfDoo9assVw5G9xr+HDo2tXax3uSL7oiSfS1gDVBn9cGlgVbAHQPvO8GlBeRKiJSDHgcuD2nA4jItSKSKiKp/sDVJbPx422c9+yaVGanRw845hhrBhnqsdpvv1lCv+su67SUmmp/BTgHsWteeTvQXkTmAe2BdUA6cCMwNbi+PhRVHauqKaqaUq1atRiF5Fzhkp4OTz8N7dpBmza527dECestO2eONYUMNmcOtG5t85Q+/TS8/jpUqBC7uF3iiyTRrwPqBH2uHVj2B1Vdr6rdVbUVMDSwbDvQDugvIquxevy/i0icBmB1Lr7ef9+mCszt3XymPn1s3JuHH7bPqvDsszaksKrVzd98sw8D4A4XSaKfAzQUkQYiUgq4DHgveAMRqRqopgEYgrXAQVX/pqp1VbU+dtc/QVVzmJzMueQ1apT1HO3ePfy2oZQubZ2apk2zu/pevSyxd+wI331nww04F0rYRK+qaUB/4CNgKTBJVReLyDAR6RLYrAOwTESWYw9eH8yneJ1LSAsW2CiO/ftHN5bM9dfbuDdnn21DDTz8sE1WUqVK7GJ1ycc7TDlXAK66yurO1661XqjReOIJa6L5yivQoUNMwnNJIKcOU95Nwrl8tmYNvPaadWCKNsmDVd/89JMneRc5T/TO5aOMDJtUpGRJm2rPuXhIiEHNnEtUzzxjD0/Hji34+V+dy+SJ3hVqP/wAH3xgXfhPPTX82DCFyZIl1oHpggvgmmviHY0ryjzRu0InPd3anD/7rM1DmqlkSWtCeMYZ9mrXrmBmL8qLAwegd28oX96GPPC27S6evI7eFRpbt9pYLccea935lyyxiaZXrbK7+oEDbfq9Bx+EM8+0ZoZnnGHzkX7xhSXXwuKf/7Tx5l98EWrUiHc0rqjz5pWFzI4ddhdYlIaNnTfP7t7/8x/Yt89ak/Tvb8k+VJvzHTsssU+fbq/5861naOXK8NRT8Le/RX8HvX27TWKdl6qir76C00+3VjYvvxxdHM5FyptXJojdu23gqg4dYMuWeEeT/955x+rdW7eGiROti//ChZa8L744+45FFStavffjj1uP0C1b4O234fjjbRjfiy+GTZvyFtOBAzBypPVgbdzYptnLjV274O9/h3r1rCesc4WBJ/pCZOpUG4Xwq6+gbVt7EJmsZs6Ebt0sIT/5JKxbZ9PqNWuW+7IqV4aLLrK7/Ecftfr9Jk1g8uTclfPJJ9CiBdxxh83qBHDaafbXRqR/+Ga2cZ8wwf4yc65QUNVC9TrxxBO1qOrRQ7VGDdWvvlKtXl21YkXVTz6Jd1Sxl5Gh2rataq1aqnv2xL78xYtVU1JUQfWyy1S3bMl5+9WrVbt3t+2PPVZ1yhRbvnWr6gUX2PJLL1XdsSPnct5917YdPDg25+FcbgCpmk1ejXtiz/oqqon+999VjzxS9YYb7PPq1apNm6oWL676/PPxjU1Vdf58+yK69dboy3r7bfvNe/HF6MvKzoEDqsOHq5YooVqzpur//nf4Nnv2qP7zn6qlS9vP/sEHVffu/fM26emqjzxi16FhQ9UFC0Ifb+NG1WrVVFu0UN2/P/bn41w4nugTwOTJdjWmTTu0bMcO1fPOs+UDB6qmpRV8XIsWqV5yicVQooT9m3nHmxcHD6qecIK9Dh6MXZzZmTdPtXlzi7tvX9Xt2+0vinfeUW3Q4NDd+i+/5FzO55+rHn20fSmMG/fndRkZql26qB5xhP28nIsHT/QJ4LLLVKtWPTz5HTxod9Fg1Qg7d0ZWXkaG6vffq771VvgkFsrSpRaTiGr58qr/+IfdtTZurFqvnuru3bkvU9Xu4sHiKij796sOHWp35bVrq3bsaDE0bvznL9ZwNmxQPfPMQ18av/9uy196yZY98UT+xO9cJDzRF3J79qiWK6far1/22zz3nCWq5s1DJ+6MDNUfflAdM8buUKtXt6ub+Tr2WNVrrlF97TXV9euzP87y5aq9e6sWK6ZatqzqkCF/ruOeOdPKu/PO3J/n779bvXzbthZvQfv2W9VGjVQrVFB98kmr3smttDT70hNRbdZMdepU+zmdcYZV8zgXL57oC7l33rEr8fHHOW/34YeWpGrWVJ09W3XlSrtDvvxy1b/85VBSr1XLkvXLL6vOmmVJrUsXe7ibuc3xx6tef73q66/bneqPP9pdarFiqmXKqN5xh+qmTaHjuPpq+9LJrr46OyNG2LE//zx3+8XSwYOqu3ZFX86HH6pWqWLnU7Gi6s8/R1+mc9GIOtEDnYBlwEpgcIj19YBpwEJgBlA7aPl3wHxgMXB9uGMVxUTfu7dq5cqR3WEuXnyobjnzVaOGVbO88ILdkWd3t5yWppqaqvrYY6qdO1uVTGYZxYpZ/fPAgZb4c7Jli1UztW0b+V3s1q2qRx2lev75kW2fCH75xf56eu+9eEfiXM6JPmzPWBEpDiwHOgJrsakFe6nqkqBt3gCmqOq/RORM4EpVvSIw9aCo6n4RKQd8D5yiquuzO15R6xm7fz9Urw6XXBJ5L8rNm23yiTp1bAiAE07IW0/QtDSYO9c6KP3+O9x4Ixx9dGT7vvqqdQx6/nm47rrw2995p3VEWrAgb23lnXM5y6lnbCSJvh1wv6qeG/g8BEBVHw7aZjHQSVXXiIgAO1S1QpZyqgDzgLae6A95/33r5Tl1Kpx3XryjiZyqTWc3d6517KpZM/tt16yBhg2hZ0/4178KLkbnipJoh0CoBawJ+rw2sCzYAiBzyuNuQPlAYkdE6ojIwkAZj4RK8iJyrYikikjq5s2bIwgpeUyebF36zzor3pHkjgg89xzs3Wu9QXNy//32xTBsWIGE5pzLIlZDINwOtBeReUB7YB2QDqCqa1S1OfBXoI+IHDaWn6qOVdUUVU2pVq1ajEIq/A4csPFeuna1AbQSzfHHw913w3//Cx9/HHqbxYth/Hi46SYb/8U5V/AiSfTrgDpBn2sHlv1BVderandVbQUMDSzbnnUbrI7+/6KKOIlMn26jJF5ySbwjybvBg+G44+CGG+zuPqu774Zy5exf51x8RJLo5wANRaRB4OHqZcB7wRuISFURySxrCDAusLy2iJQJvK8EnIa13nFYtU358tCxY7wjybsjjrAHsqtW2Tjxwb76Ct57zx7EVq0an/iccxEkelVNA/oDHwFLgUmqulhEholIl8BmHYBlIrIcqAFk/pdvBMwWkQXA58BIVV0U43NISGlpNrTuhRcW3lmSInXGGdYC59FHYelSW6Zq0+jVrAkDBsQ3PueKOp94JE6mTbNWK2+/bUPsJrrNm62ZZ5MmMGMGTJlizx4ibX7pnIuOTzxSCL3xBpQtC+eeG+9IYqNaNbuj/+IL6w8wZIg1qbzqqnhH5pzzycHjID0d3nrL2s+XKRPvaGLnyiutnfwNN9g5vvGGTejtnIsvv6OPgy++sKqORG5tE0qxYlZVU6wYnHSSTennnIs/v6OPg8mT7U4+kXrCRqpxY/jyS6hbN/oJup1zseGJvoBlZMCbb0LnzlZHn4zatIl3BM65YF51U8BmzYING5Kv2sY5V3h5os/Gk0/CaafB7t2xLXfyZOtkdP75sS3XOeey44k+C1VrGnjbbdazM5ajLWZW23TqZD1inXOuIHiiD5KeDtdfDyNGWCefk0+Gp56yBB0L334La9d6tY1zrmB5og84cAAuvxzGjrU7+jFjYOBAWLHCxoqPhcmTbZTKCy+MTXnOORcJT/TAnj3WXX/SJHjsMXjoIWsa2L071K4No0ZFfwxVS/TnnGPjzzvnXEEp8ol++3ZLvh9/DC+9BLfffmhdyZLQv7+NS7MoyqHY5s6Fn3/2ahvnXMEr0ol+40bo0MHqzl9/Ha6++vBt+vWzzk1PPRXdsSZPhhIloEuX8Ns651wsFdlEv3q1NZ9cscLmbc3uTrtyZejTB/79bxu2IC+2b4dXXrFx5ytVynPIzjmXJ0Uy0S9ZYkl+61b49NPwE3/ccgvs3w8vvJC34w0ZAlu2wAMP5G1/55yLRpFL9B98AKefbk0pP/8c2rULv0+jRtb2ffRoa52TG19/bV8Qt94KrVvnLWbnnItGRIleRDqJyDIRWSkig0Osryci00RkoYjMEJHageUtReRrEVkcWNcz1icQqZ074ZprbIyZo4+2gbeaNYt8/wEDbOiCSZMi3+fgQWuPX6sWDBuW+5idcy4WwiZ6ESkOjAbOAxoDvUSkcZbNRgITVLU5MAx4OLB8D/B3VW0CdAJGichRsQo+UtOmWVJ/5RWrRklNhWOPzV0Z55xjd/ZPPmlNJSMxapS11nnmGZsg2znn4iGSO/o2wEpVXaWqB4CJQNcs2zQGPgu8n565XlWXq+qKwPv1wCagWiwCj8Tu3XDTTTZlX5kyNqDYQw/ZWDO5JWJ39d99Z38NhLN6Ndx/v7XPT4apAp1ziSuSRF8LWBP0eW1gWbAFQPfA+25AeRGpEryBiLQBSgE/Zj2AiFwrIqkikro5r01bsvjiC2jR4lAP13nzbEiDaPTuba1wwnWgUrX29yJ2N++cc/EUq4extwPtRWQe0B5YB6RnrhSRo4FXgStV9bCRY1R1rKqmqGpKtWrR3fDv3WsDkrVvb58//xyeeCI2U/YdeaTVub/zDvz0U/bbvfWWNdkcNgzq1In+uM45F41IEv06IDhd1Q4s+4OqrlfV7qraChgaWLYdQEQqAO8DQ1X1m5hEnY3Zs6FVK6tHv+EGWLAA/u//YnuMG2+0qfKefTb0+p07rTlmy5b2r3POxVskiX4O0FBEGohIKeAy4L3gDUSkqohkljUEGBdYXgp4G3tQOzl2YR9u2TI45RQbt+aTT6wpZH48AK1dG3r0sOESdu06fP0998Cvv1qTyhI+f5dzrhAIm+hVNQ3oD3wELAUmqepiERkmIpkd+jsAy0RkOVADeDCw/FLgdKCviMwPvFrG+iQAjj8eXnzRWrmcfXZ+HOGQAQPszn38+D8vnzPH7vRvvNGn03POFR6ikbYVLCApKSmampoa7zDCOuUU2LQJli+3qpy0NEvuGzbA0qU+QqVzrmCJyFxVTQm1rsj1jI2VgQPhxx/toSvYnfy8eTb4mSd551xh4ok+j7p1sxY1Tz4Ja9bAP/4B553nwxA75wofT/R5VKIE3HwzTJ9uE5Skp9sDYJF4R+acc3/miT4K11xjbetTU+G++6BBg3hH5Jxzh/NEH4VKlaxz1mmn2b/OOVcYeUvvKA0fHu8InHMuZ35H75xzSc4TvXPOJTlP9M45l+Q80TvnXJLzRO+cc0nOE71zziU5T/TOOZfkPNE751yS80TvnHNJLqJELyKdRGSZiKwUkcEh1tcTkWkislBEZohI7aB1H4rIdhGZEsvAnXPORSZsoheR4sBo4DygMdBLRBpn2WwkNl1gc2AY8HDQuseAK2ITrnPOudyK5I6+DbBSVVep6gFgItA1yzaNgc8C76cHr1fVaUCI2VWdc84VhEgSfS1gTdDntYFlwRYA3QPvuwHlRaRKpEGIyLUikioiqZs3b450N+eccxGI1cPY24H2IjIPaA+sA9Ij3VlVx6pqiqqmVKtWLUYhOeecg8iGKV4H1An6XDuw7A+qup7AHb2IlAMuVtXtsQrSOedc3kVyRz8HaCgiDUSkFHAZ8F7wBiJSVUQyyxoCjIttmM455/IqbKJX1TSgP/ARsBSYpKqLRWSYiHQJbNYBWCYiy4EawIOZ+4vIF8AbwFkislZEzo3xOTjnnMuBqGq8Y/iTlJQUTU1NjXcYzjmXUERkrqqmhFrnPWOdcy7JeaJ3zrkk54neOeeSnCd655xLcp7onXMuyXmid865JOeJ3jnnkpwneuecS3Ke6J1zLsl5onfOuSTnid4555KcJ3rnnEtynuidcy7JeaJ3zrkk54neOeeSXESJXkQ6icgyEVkpIoNDrK8nItNEZKGIzBCR2kHr+ojIisCrTyyDd845F17YRC8ixYHRwHlAY6CXiDTOstlIYIKqNgeGAQ8H9q0M3AecDLQB7hORSrEL3znnXDiR3NG3AVaq6ipVPQBMBLpm2aYx8Fng/fSg9ecCn6jqb6q6DVMDXbwAABg4SURBVPgE6BR92M455yIVSaKvBawJ+rw2sCzYAqB74H03oLyIVIlwX+ecc/koVg9jbwfai8g8oD2wDkiPdGcRuVZEUkUkdfPmzTEKyTnnHESW6NcBdYI+1w4s+4OqrlfV7qraChgaWLY9kn0D245V1RRVTalWrVouT8E551xOIkn0c4CGItJAREoBlwHvBW8gIlVFJLOsIcC4wPuPgHNEpFLgIew5gWXOOecKSNhEr6ppQH8sQS8FJqnqYhEZJiJdApt1AJaJyHKgBvBgYN/fgOHYl8UcYFhgmXPOuQIiqhrvGP4kJSVFU1NT4x2Gc84lFBGZq6opodZ5z1jnnEtynuidcy7JeaJ3zrkk54neOeeSnCd655xLcp7onXMuyXmid865JOeJ3jnnkpwneuecS3Ke6AvK7t2wf3+8o3DOFUGe6AvC3r3QujWcfTZkZMQ7GudcEeOJviA8/jisWAFffgmvvRbvaJxzRYwn+vy2Zg089BB07w5t2sCdd8KuXfGOyjlXhHiiz2933AGq8MQT8MwzsGEDPPBAvKNyzhUhnujz0+efw+uvw113Qb16dkffty88+SQsXx7v6JxzRYQn+vySlga33AJ161p1TaaHH4bSpeG22+IXm3OuSIko0YtIJxFZJiIrRWRwiPV1RWS6iMwTkYUi0jmwvJSIvCIii0RkgYh0iHH8hdeLL8LChfYg9sgjDy2vWRPuuw/ef99ezjmXz8LOMCUixYHlQEdgLTYlYC9VXRK0zVhgnqqOEZHGwFRVrS8iNwEpqnqliFQHPgBOUtVs2xgmxQxTv/0GDRtCixYwbRqI/Hn9gQPQvLk1tfz+eyhVKj5xOueSRrQzTLUBVqrqKlU9AEwEumbZRoEKgfcVgfWB942BzwBUdROwHQgZSIH58Ufo0gVmz86/Y9x7L2zfDk89dXiSB0vso0ZZk8unnsp9+QsXQufO8PHH0ccaqYMHYfBguP/+2JS3axdcfjl8/XVsynN/Fuvr5RKbqub4Ai4BXgr6fAXwbJZtjgYWYXf824ATA8uvBd4ASgANsER/cYhjXAukAql169bVfNW5syqoli6t+sYbsS9/wQLVYsVU+/cPv+2FF6qWK6e6fn3k5U+davuAavHiqs8/n/dYI7V9u+o559gxQfXLL6Mvc/BgK+v441X374++PHdIflwvV+gBqZpdHs9uheYu0d8GDAq8bwcswf5aKAE8CcwH3gWmAhfldLwTTzwx/34SU6bYKQ8dqnrKKfZ+xAjVjIzYlJ+Rodq+vWqVKqpbt4bffsUK1VKlVP/+98jKf/ZZ+xJp1Ur1hx8OfWkNGqSanh5V6NlavVq1SRPVEiXs+LVrq7ZurZqWlvcyly+3827RwuJ//PHYxVvU5cf1cgkh2kTfDvgo6PMQYEiWbRYDdYI+rwKqhyhrFtA4p+PlW6Lft0/1r39VPeEE1QMHVPfuVb3sMvsRXH21LYvW669beWPGRL5P5p3t119nv01amuqtt9p2F16oumuXLT940P5yANWLLlLdvTu6+LOaPVu1Rg3VihVVP/3Ulv3nP3a8sWPzXu4FF6iWL29/yXTubO9//TU2MRdl+XW9XEKINtGXCCTuBkApYAHQJMs2HwB9A+8bYXX0AhwJlA0s7wjMDHe8fEv0I0bY6X700aFl6emq99xjy888U3XbtryX//vvqnXq2F1qbu6edu1S/ctfVFNSQt+V79plyR1UBwwIXfZTT6mKqJ54Yu6qgXIyebJVbzVooLpkyaHlGRmqp52mWrWq6m+/5b7cqVPtXB591D4vW6ZasqTqlVfGJu6iKr+ul0sYUSV625/OWMubH4GhgWXDgC6B942BrwJfAvOBcwLL6wPLgKXAp0C9cMfKl0S/bp1q2bKqXbuGXj9+vCWbE05Q/fHHvB3j3nvtxzlzZu73/fe/bd+XX/7z8rVrrZqmWDHV0aNzLuO99+wc69Sx5wR5lZGh+sgjFk+7dqobNx6+zbx5FtOtt+au7P37VY87zl7B9fJ33GHHmz0773EXVVmv16ZNh2+T1+vlEkrUib4gX/mS6K+4wuqEV67MfpsZM1QrVVKtVk111qzclf/TT3Y3ddlleYsvI8OeGVSvbg/SVFW/+87u9MuVs7vgSGTuU7585PsEO3BA9Zpr7NeiZ0+r3srO9dfbw+Dvv4+8/Mces7KzxrZjh2rNmqonn5x/zxqSUX5fL5dQinai/+orO8277w6/7bJlVo9/xBGqEydGfoyLL1Y98kjVX37Je5ypqVb9cttt0d2dr12r2rJlZH8FBNu2TfWss+xndc894RPu5s2qRx1l+0TyMPvXX+0L6PzzQ68fP96OPX585DEXZfl9vVzCySnRh+0wVdBi2mEqPR1OPtkGEvvhByhXLvw+W7ZAt242pPCAAXDccTlvv3mz9XR94AEYOjS6eK+9FsaNs45UrVvD//4HRx+d+3J274ZevWDKFLjmGisrJ6rw7LOwcqX16O3TJ7LjPPss3HwzvPmmjc6ZkyuvtCGaFy+2zmRZZWTAKafAzz/DsmVQocLh2xSk77+335f69eMbRyi//AKdOuX9er31lv2OJ5P5821okRNOiHckcZNTh6m438FnfcX0jv7FF+2O57XXcrffvn1W3ZPZDjncq1mznP9sjtSmTVaF0b179C1oglvqRPKqXFl1+vTcHePgQdWmTVXr11fdsyf77b75xo5x1105l/ftt7bdHXfkLo5Y27hRtUKF8OcVLz17WpVefl2vRJN5vcqUsYfSRRRFsupm2zarbz/11Lz/qbpli+qGDeFfsWiamengwdiVpWotLSI5h7x+UX32mf0aDRsWen16uupJJ6kefbTqzp3hy7vqKnsw/sMPeYsnFq6+2uqzczqveNmyxZ435fXBarjrlYiuvtr6DZx4op3bI48UyeqpopnoBwywOu/vvotNeS57l1xid1M//3z4uldesV+zCRMiK2vDBrs7O++8mIYYsTlz7Pfm9ttVe/TI/rziZdQo+3kuXJj3MjKvVzTPlAqLzOs1aJDdrPTsaT+fa66J7Q1YAih6iX7xYrsju+666Mty4a1eba2OLr30z8u3b7cOPO3a5a41zeOP26/mlCmxjTOc9HSLtUYNawmUeV49exZsHNnJyLCqlzZtoiunsJ1XXmW9XpnLhg6135+zzoqub0yCKVqJPiND9eyzrYXB5s3RleUid//99us0Y8ahZYMG2d3WnDm5K2v/fuvT8Ne/2vOSgjJhgp3DK68cWhbqvOIl81lHLHq5FqbzyqtQ1ytTZt+YRo1UV60q8NDioWgl+rffttN6+unoynG58/vvqnXrqjZvbs8Zli61etOrr85beR9+qH+MRVQQdu60B+Ft2vz5r489e1Tr1Tt0XvF0zTXW7DaSZx3hZL1eiSa76xVs+vS8941JQEUn0e/ZYy0KmjRJzF/eRPfGG/Yr9eyzqueea3XtoXrWRqpLF2tdsm5d7GLMzp13WuzffHP4uszzyk2/hFjbtct+FlddFbsyM8/ruediV2ZByel6BfvhB9Vjj7W+Ma+/XjCxxUnRSfTDh9spTZuW9zJc3mVkqJ5xhv2nAtUnn4yuvJUrrYVJ7972xR3ulddetcuX25/5ffuGXp95XpUrW6uXvIi2FcjLL9vPNJZ3prE4r2iPnxfhrldWmzdb6ztQffDBpG2RUzQS/S+/WEuCiy/O2/4uNhYutAfhjRrFptXD3XdrxH0BqlXL25f8+eeHH0Ez87xuvDH35U+caA8M8zIsRaZ27exnGusklXlenTvHfvTT7KSlWau4mjXz73pltW+f6uWX2+/JQw/l/pgJIKdEX6Jg+mwVgCpVbBLuvn3jHUnR1qwZfPghHHMMlCwZfXn/+Af85S+wbVv4bf/7Xzj3XBg71nriRmLqVJu7d+RIm883O82awY03wujR1oO5RYvwZavCQw/BPffYTGM33QRLllgPztxYvNhm4nr88dAzlkWjWTPrMXvTTXD66dYb+y9/ie0xgu3aZb22338fqlfP+/V67LGcr1dWRxwB//437NsHw4fD3/4Gdevm7RwSUXbfAPF65evEIy65bdtmLa5AdciQ8FU5+/erNmwY+SxXv/1mk8q0bx/+znr/ftU+fSyW3r1V33/f3j/wQKRnc8jAgVZVEWpkyliZMsWeAdSurTp/fv4cY80aG8a7eHGbs2H7dtWOHXN/vbKOfpobq1fbX/5ZmwInAYpE1Y1zqlZd1K+f/Wr36JFzV/9HH7XtPvgg8vKff972yenB3tat9mUA1owx80uhe3cb/G7NmsiPt2+ffbn06BH5Pnk1f75qrVqW8N9/P7Zlz517aGTVDz88tPzAAdVrr82/6xVKMjQtDcETvStaMjJsSGQRG/p4w4bDt1m/3hLahRfmruy0NBsdtE4da6KY1YoVdtdZqpTNMxBs1Sp7UN2rV+THmzRJD5swJz+tW2dTDxYrpvrMM7Ep89137Quubt3QPXrz83qFUpiazMZQ1Ike6IRNILISGBxifV1gOjAPWAh0DiwvCfwLmzh8KVmmIAz18kTvYubNN+3P9Pr1Dx+HvU8fS8YrVuS+3Jkz7b/OvfcevrxyZbsD/+KL0Pv+4x+aqwlqzjnHEmRBjtO/e7c1bQXVm2/O+3yzGRnW8krExjsK9/D0rbfy53qFMnmyxr3JbIxFleiB4tjMUsdwaCrBxlm2GQvcEHjfGFgdeH85MDHw/khgNVA/p+N5oncx9e231rqjQgXVjz+2ZV9/bb/6gwfnvdxevezuPLPX5auvWiI67rick1Fuppz86SdLkvffn/c48yotzZ4NgLVyyW0nrYMHrYUSWJVVqL9+Qsmv65VVZtPSSpXi07Q0H0Sb6COZHPwF4K6g7WcF3vcC/ofNO1sFm46wck7H80TvYu7nn20o6eLFrY79pJOsvjhzkvW8WLPGqiO6dVO97z77r9Shg9XPhzNxom3//PM5b3fvvZbo4zmo2nPP2c+tRYvIny3s2KHaqZOd45135v6vkfy4XqFE02S2EMop0YedeERELgE6qeo1gc9XACerav+gbY4GPgYqAWWBs1V1roiUBF4Fzgrc0Q9U1bEhjnEtcC1A3bp1T/z5559zjMm5XNu5E3r2tKafAK++Cr17R1fmgw9a00mwyT/GjoVSpcLvpwodOlizyeXLoXLlw7dJT7dJT5o2hQ8+iC7OaH34IVx6qU3Ecu654bf/5htYsQLGjIF+/fJ2zPy4XqHccos1mf3uu8iazBZiUU08AlwCvBT0+Qrg2Szb3AYM0kN39EuAYsCpwGtYXX11rJ7/mJyO53f0Lt8cPGgDrfXuHZuOR3v3WkejESNyX978+fbAs3//0Os/+MDuiAvLRBoLF9qddd264V+NGx+qdolGrK9XKJlNZk8/PeF7zFIAVTeLgTpBn1cFEvto4Iqg5eOAS3M6nid6V2TccINVHYRqiXLxxdbTN6/txV3kImkymwBySvTFIviLYA7QUEQaiEgp4DLgvSzb/IJVzyAijYDSwObA8jMDy8sCbYEfIjimc8lv+HCbG/fWW606J9OmTfDuu/D3v0dWFeSic8010LIl3H47/P57vKPJF2ETvaqmAf2Bj7AmkpNUdbGIDBORLoHNBgH9RGQB8F+gb+AbZjRQTkQWY18Yr6jqwvw4EecSTpUqNqn89Ok2wXqmCRMgLQ2uvjp+sRUlxYvDM8/AmjXwyCPxjiZfhH0YW9BSUlI0NTU13mE4VzDS0qB1a9ixA5YuhTJloFEjqFoVvvwy3tEVLZdfDm+9ZdehQYN4R5NrOT2MjaTqxjmXX0qUgKefhl9+sYG6Zs2CZcusOsEVrEcftbv722+PdyQx54neuXjr0MGaL44YAcOGQfny0KNHvKMqemrXhqFD7a7+00/jHU1MedWNc4XBL7/ACSfA3r02DPILL8Q7oqJp3z5o0sSGkh47Nvyw0JUqWVVbLPzyC2zfDs2b52n3nKpukmc8eucSWd26MGQI3Htv3jsZueiVLg1PPgldu8Jpp0W2z5Ah9lC9WBQVJKmpcOGF9sWxaJFVIcWQJ3rnCouhQ6F7d7ujdPHTpQvMnw8bN4bfdtIkePhh+PFHGD/eHqbn1jvv2IPg6tXhjTdinuTBE71zhUexYp7kC4tIh0Po2BGOPx7uusuqXt591xJ2JFThiSfgjjugTRvbt0aNvMecA38Y65xzeSViiXryZFiwAE4+2aaLDOfgQbjhBmvhc/HF1pcin5I8eKJ3zrnode8On39uD9Pbtcu51c6OHXDBBfbAffBgeP31vFX55IIneueci4WTToLZs+3BeqdO8OKLh2+zejWceip89hm89JLV70fzEDdCnuidcy5W6tWDr76Cs8+2ZrJ33gkZGbbu22+tamftWht+uQCHuPCHsc45F0sVKsCUKTbW/WOPWYuc7t2tt/PRR8OMGbFrex8hT/TOORdrJUrYhCYNG8KgQdbbtl07a1lTrVrBh1PgR3TOuaJABAYOtOaXX35pneFKl45LKJ7onXMuP3XubK848oexzjmX5DzRO+dckoso0YtIJxFZJiIrRWRwiPV1RWS6iMwTkYUi0jmw/G8iMj/olSEiLWN9Es4557IXNtGLSHFsSsDzgMZALxFpnGWze7ApBlthc8o+B6Cqr6lqS1VtCVwB/KSq82N5As4553IWyR19G2Clqq5S1QPARKBrlm0UqBB4XxFYH6KcXoF9nXPOFaBIWt3UAtYEfV4LnJxlm/uBj0XkZqAscHaIcnpy+BcEACJyLXAtQN26dSMIyTnnXKRi9TC2FzBeVWsDnYFXReSPskXkZGCPqn4famdVHauqKaqaUi0OnQmccy6ZRZLo1wF1gj7XDiwLdjUwCUBVvwZKA1WD1l8G/DfvYTrnnMursHPGikgJYDlwFpbg5wCXq+rioG0+AF5X1fEi0giYBtRSVQ3c2a8B/k9VV4UNSGQz8HNeTwj7gtkSxf6FgZ9D4eDnUDj4OUSmnqqGrBIJW0evqmki0h/4CCgOjFPVxSIyDEhV1feAQcCLIjIQezDbVw99g5wOrIkkyQeOF1XdjYikZjdBbqLwcygc/BwKBz+H6EU0BIKqTgWmZll2b9D7JcCp2ew7A2ib9xCdc85Fw3vGOudckkvGRD823gHEgJ9D4eDnUDj4OUQp7MNY55xziS0Z7+idc84F8UTvnHNJLmkSfbgRNhOBiKwWkUWBkT5T4x1PpERknIhsEpHvg5ZVFpFPRGRF4N9K8YwxnGzO4X4RWRc0+mp8Z4/IgYjUCYwgu0REFovIrYHlCXMdcjiHhLkOACJSWkS+FZEFgfP4Z2B5AxGZHchRr4tIqQKLKRnq6AMjbC4HOmJj8cwBegWafSYMEVkNpKhqQnUOEZHTgd3ABFVtGlj2KPCbqo4IfPFWUtW74hlnTrI5h/uB3ao6Mp6xRUJEjgaOVtXvRKQ8MBe4COhLglyHHM7hUhLkOgCIiABlVXW3iJQEvgRuBW4D3lLViSLyPLBAVccUREzJckcfyQibLp+o6kzgtyyLuwL/Crz/F/YfttDK5hwShqr+qqrfBd7vApZiAxImzHXI4RwSiprdgY8lAy8FzgQmB5YX6LVIlkQfaoTNhPsFwX4ZPhaRuYERPRNZDVX9NfB+A1AjnsFEoX9gMp1xhbnaI5iI1AdaAbNJ0OuQ5Rwgwa6DiBQXkfnAJuAT4Edgu6qmBTYp0ByVLIk+WZymqq2xSV5uClQnJLzAcBiJWEc4BjgWaAn8Cjwe33DCE5FywJvAAFXdGbwuUa5DiHNIuOugqumBCZdqYzUOJ8QznmRJ9JGMsFnoqeq6wL+bgLexX5BEtTFQ55pZ97opzvHkmqpuDPyHzQBepJBfj0B98JvAa6r6VmBxQl2HUOeQaNchmKpuB6YD7YCjAoNEQgHnqGRJ9HOAhoGn2qWwYZHfi3NMuSIiZQMPoBCRssA5QMjx+xPEe0CfwPs+wLtxjCVPMhNkQDcK8fUIPAB8GViqqk8ErUqY65DdOSTSdQAQkWoiclTgfRmskchSLOFfEtisQK9FUrS6AQg0uRrFoRE2H4xzSLkiIsdgd/Fgg839J1HOQUT+C3TAhmLdCNwHvIPNUVAXG3b6UlUttA87szmHDlh1gQKrgeuC6rsLFRE5DfgCWARkBBbfjdVxJ8R1yOEcepEg1wFARJpjD1uLYzfTk1R1WOD/+ESgMjAP6K2q+wskpmRJ9M4550JLlqob55xz2fBE75xzSc4TvXPOJTlP9M45l+Q80TvnXJLzRO+cc0nOE71zziW5/wfjP1zCmzNTGAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting...\n",
            "7/7 [==============================] - 20s 2s/step\n",
            "\n",
            "Confusion matrix:\n",
            "[[202  21]\n",
            " [ 15  88]]\n",
            "\n",
            "Evaluating...\n",
            "7/7 [==============================] - 11s 1s/step - loss: 1.1733 - accuracy: 0.8896\n",
            "\n",
            "Per class accuracy:\n",
            "0: 0.905829596412556\n",
            "1: 0.8543689320388349\n",
            "Average class accuracy: 0.8800992642256955\n",
            "F1 score: [0.91818182 0.83018868]. Avg F1: 0.8741852487135505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart()\n",
        "# start_colab()\n",
        "# extract_data()\n",
        "# fold_p2m = create_folds_p2m()\n",
        "# save_folds([fold_p2m])\n",
        "\n",
        "gen_train = Generator_V('Train', batch_size, time_frames)\n",
        "gen_val = Generator_V('Validation', batch_size, time_frames)\n",
        "gen_test = Generator_V('Test', batch_size, time_frames)\n",
        "\n",
        "model, save_dir, epoch = build_model(epoch, print_model=False)\n",
        "\n",
        "callbacks = set_callbacks()\n",
        "fit_model(list(len(gen_train.labels) / np.sum(gen_train.labels, axis=0)), epoch)\n",
        "gen_test = predict()\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_z9YA0YBBO_",
        "outputId": "5e6f8eae-b557-4760-ad9c-003e3842e39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "BUILDING GENERATOR...\n",
            "Done\n",
            "Building model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 7s 0us/step\n",
            "219070464/219055592 [==============================] - 7s 0us/step\n",
            "Train weights: {0: 2.5943563, 1: 1.6272124}\n",
            "Epoch 1/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 5.8555 - accuracy: 0.4932\n",
            "Epoch 00001: val_loss improved from inf to 1.60428, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/001.h5\n",
            "59/59 [==============================] - 146s 2s/step - loss: 5.8555 - accuracy: 0.4932 - val_loss: 1.6043 - val_accuracy: 0.2474 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.3727 - accuracy: 0.5007\n",
            "Epoch 00002: val_loss improved from 1.60428 to 1.51799, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/002.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.3727 - accuracy: 0.5007 - val_loss: 1.5180 - val_accuracy: 0.4536 - lr: 1.0000e-04\n",
            "Epoch 3/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2498 - accuracy: 0.5075\n",
            "Epoch 00003: val_loss improved from 1.51799 to 1.51771, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/003.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.2498 - accuracy: 0.5075 - val_loss: 1.5177 - val_accuracy: 0.4227 - lr: 1.0000e-04\n",
            "Epoch 4/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2249 - accuracy: 0.5262\n",
            "Epoch 00004: val_loss improved from 1.51771 to 1.51446, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/004.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.2249 - accuracy: 0.5262 - val_loss: 1.5145 - val_accuracy: 0.4777 - lr: 1.0000e-04\n",
            "Epoch 5/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2160 - accuracy: 0.5007\n",
            "Epoch 00005: val_loss did not improve from 1.51446\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.2160 - accuracy: 0.5007 - val_loss: 1.5175 - val_accuracy: 0.4467 - lr: 1.0000e-04\n",
            "Epoch 6/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2240 - accuracy: 0.5340\n",
            "Epoch 00006: val_loss did not improve from 1.51446\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.2240 - accuracy: 0.5340 - val_loss: 1.5180 - val_accuracy: 0.4296 - lr: 1.0000e-04\n",
            "Epoch 7/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2120 - accuracy: 0.5459\n",
            "Epoch 00007: val_loss did not improve from 1.51446\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.2120 - accuracy: 0.5459 - val_loss: 1.5193 - val_accuracy: 0.4192 - lr: 1.0000e-04\n",
            "Epoch 8/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2109 - accuracy: 0.5466\n",
            "Epoch 00008: val_loss improved from 1.51446 to 1.51215, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/008.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.2109 - accuracy: 0.5466 - val_loss: 1.5122 - val_accuracy: 0.5945 - lr: 1.0000e-04\n",
            "Epoch 9/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2021 - accuracy: 0.5816\n",
            "Epoch 00009: val_loss improved from 1.51215 to 1.50412, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/009.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.2021 - accuracy: 0.5816 - val_loss: 1.5041 - val_accuracy: 0.6804 - lr: 1.0000e-04\n",
            "Epoch 10/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2072 - accuracy: 0.5095\n",
            "Epoch 00010: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.2072 - accuracy: 0.5095 - val_loss: 1.5154 - val_accuracy: 0.4674 - lr: 1.0000e-04\n",
            "Epoch 11/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1997 - accuracy: 0.5755\n",
            "Epoch 00011: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1997 - accuracy: 0.5755 - val_loss: 1.5041 - val_accuracy: 0.6976 - lr: 1.0000e-04\n",
            "Epoch 12/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.2068 - accuracy: 0.5092\n",
            "Epoch 00012: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.2068 - accuracy: 0.5092 - val_loss: 1.5145 - val_accuracy: 0.5361 - lr: 1.0000e-04\n",
            "Epoch 13/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1982 - accuracy: 0.5931\n",
            "Epoch 00013: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1982 - accuracy: 0.5931 - val_loss: 1.5118 - val_accuracy: 0.5773 - lr: 1.0000e-04\n",
            "Epoch 14/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1974 - accuracy: 0.5850\n",
            "Epoch 00014: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1974 - accuracy: 0.5850 - val_loss: 1.5195 - val_accuracy: 0.4192 - lr: 1.0000e-04\n",
            "Epoch 15/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1847 - accuracy: 0.5381\n",
            "Epoch 00015: val_loss did not improve from 1.50412\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1847 - accuracy: 0.5381 - val_loss: 1.5132 - val_accuracy: 0.5773 - lr: 1.0000e-04\n",
            "Epoch 16/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1921 - accuracy: 0.5880\n",
            "Epoch 00016: val_loss improved from 1.50412 to 1.50387, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/016.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.1921 - accuracy: 0.5880 - val_loss: 1.5039 - val_accuracy: 0.6495 - lr: 1.0000e-04\n",
            "Epoch 17/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1946 - accuracy: 0.6128\n",
            "Epoch 00017: val_loss did not improve from 1.50387\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1946 - accuracy: 0.6128 - val_loss: 1.5064 - val_accuracy: 0.5842 - lr: 1.0000e-04\n",
            "Epoch 18/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1970 - accuracy: 0.5826\n",
            "Epoch 00018: val_loss did not improve from 1.50387\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1970 - accuracy: 0.5826 - val_loss: 1.5044 - val_accuracy: 0.6048 - lr: 1.0000e-04\n",
            "Epoch 19/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1943 - accuracy: 0.5928\n",
            "Epoch 00019: val_loss did not improve from 1.50387\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1943 - accuracy: 0.5928 - val_loss: 1.5091 - val_accuracy: 0.5704 - lr: 1.0000e-04\n",
            "Epoch 20/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1864 - accuracy: 0.5965\n",
            "Epoch 00020: val_loss did not improve from 1.50387\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1864 - accuracy: 0.5965 - val_loss: 1.5151 - val_accuracy: 0.5017 - lr: 1.0000e-04\n",
            "Epoch 21/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1775 - accuracy: 0.5778\n",
            "Epoch 00021: val_loss did not improve from 1.50387\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1775 - accuracy: 0.5778 - val_loss: 1.5255 - val_accuracy: 0.4296 - lr: 1.0000e-04\n",
            "Epoch 22/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1773 - accuracy: 0.5744\n",
            "Epoch 00022: val_loss improved from 1.50387 to 1.47544, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/022.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.1773 - accuracy: 0.5744 - val_loss: 1.4754 - val_accuracy: 0.7320 - lr: 1.0000e-04\n",
            "Epoch 23/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1699 - accuracy: 0.5925\n",
            "Epoch 00023: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1699 - accuracy: 0.5925 - val_loss: 1.5130 - val_accuracy: 0.5258 - lr: 1.0000e-04\n",
            "Epoch 24/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1626 - accuracy: 0.5891\n",
            "Epoch 00024: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1626 - accuracy: 0.5891 - val_loss: 1.4907 - val_accuracy: 0.6632 - lr: 1.0000e-04\n",
            "Epoch 25/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1561 - accuracy: 0.6118\n",
            "Epoch 00025: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1561 - accuracy: 0.6118 - val_loss: 1.4927 - val_accuracy: 0.6186 - lr: 1.0000e-04\n",
            "Epoch 26/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1651 - accuracy: 0.5959\n",
            "Epoch 00026: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1651 - accuracy: 0.5959 - val_loss: 1.4965 - val_accuracy: 0.6151 - lr: 1.0000e-04\n",
            "Epoch 27/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1480 - accuracy: 0.6139\n",
            "Epoch 00027: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1480 - accuracy: 0.6139 - val_loss: 1.5148 - val_accuracy: 0.5326 - lr: 1.0000e-04\n",
            "Epoch 28/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1532 - accuracy: 0.6125\n",
            "Epoch 00028: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1532 - accuracy: 0.6125 - val_loss: 1.4956 - val_accuracy: 0.5979 - lr: 1.0000e-04\n",
            "Epoch 29/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1490 - accuracy: 0.6118\n",
            "Epoch 00029: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1490 - accuracy: 0.6118 - val_loss: 1.4827 - val_accuracy: 0.6529 - lr: 1.0000e-04\n",
            "Epoch 30/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1290 - accuracy: 0.6196\n",
            "Epoch 00030: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.1290 - accuracy: 0.6196 - val_loss: 1.4940 - val_accuracy: 0.5979 - lr: 1.0000e-04\n",
            "Epoch 31/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1122 - accuracy: 0.6288\n",
            "Epoch 00031: val_loss did not improve from 1.47544\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1122 - accuracy: 0.6288 - val_loss: 1.5256 - val_accuracy: 0.4570 - lr: 1.0000e-04\n",
            "Epoch 32/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1343 - accuracy: 0.6179\n",
            "Epoch 00032: val_loss did not improve from 1.47544\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.1343 - accuracy: 0.6179 - val_loss: 1.4789 - val_accuracy: 0.6289 - lr: 1.0000e-04\n",
            "Epoch 33/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1167 - accuracy: 0.6400\n",
            "Epoch 00033: val_loss improved from 1.47544 to 1.45902, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/033.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.1167 - accuracy: 0.6400 - val_loss: 1.4590 - val_accuracy: 0.6907 - lr: 5.0000e-05\n",
            "Epoch 34/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.1010 - accuracy: 0.6407\n",
            "Epoch 00034: val_loss did not improve from 1.45902\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.1010 - accuracy: 0.6407 - val_loss: 1.4755 - val_accuracy: 0.6426 - lr: 5.0000e-05\n",
            "Epoch 35/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0999 - accuracy: 0.6417\n",
            "Epoch 00035: val_loss did not improve from 1.45902\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0999 - accuracy: 0.6417 - val_loss: 1.4854 - val_accuracy: 0.6323 - lr: 5.0000e-05\n",
            "Epoch 36/1000\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0672 - accuracy: 0.6649 - val_loss: 1.4429 - val_accuracy: 0.6942 - lr: 5.0000e-05\n",
            "Epoch 37/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0637 - accuracy: 0.6818\n",
            "Epoch 00037: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0637 - accuracy: 0.6818 - val_loss: 1.4495 - val_accuracy: 0.6976 - lr: 5.0000e-05\n",
            "Epoch 38/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0567 - accuracy: 0.6577\n",
            "Epoch 00038: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0567 - accuracy: 0.6577 - val_loss: 1.4599 - val_accuracy: 0.6907 - lr: 5.0000e-05\n",
            "Epoch 39/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0740 - accuracy: 0.6676\n",
            "Epoch 00039: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0740 - accuracy: 0.6676 - val_loss: 1.4834 - val_accuracy: 0.6323 - lr: 5.0000e-05\n",
            "Epoch 40/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0459 - accuracy: 0.6730\n",
            "Epoch 00040: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0459 - accuracy: 0.6730 - val_loss: 1.4573 - val_accuracy: 0.6701 - lr: 5.0000e-05\n",
            "Epoch 41/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0591 - accuracy: 0.6730\n",
            "Epoch 00041: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0591 - accuracy: 0.6730 - val_loss: 1.4933 - val_accuracy: 0.5911 - lr: 5.0000e-05\n",
            "Epoch 42/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0588 - accuracy: 0.6655\n",
            "Epoch 00042: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 115s 2s/step - loss: 2.0588 - accuracy: 0.6655 - val_loss: 1.4526 - val_accuracy: 0.6804 - lr: 5.0000e-05\n",
            "Epoch 43/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0317 - accuracy: 0.6869\n",
            "Epoch 00043: val_loss did not improve from 1.44285\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.0317 - accuracy: 0.6869 - val_loss: 1.4786 - val_accuracy: 0.6289 - lr: 5.0000e-05\n",
            "Epoch 44/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0230 - accuracy: 0.6927\n",
            "Epoch 00044: val_loss improved from 1.44285 to 1.43961, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/044.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0230 - accuracy: 0.6927 - val_loss: 1.4396 - val_accuracy: 0.6907 - lr: 5.0000e-05\n",
            "Epoch 45/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0246 - accuracy: 0.6869\n",
            "Epoch 00045: val_loss did not improve from 1.43961\n",
            "59/59 [==============================] - 114s 2s/step - loss: 2.0246 - accuracy: 0.6869 - val_loss: 1.4441 - val_accuracy: 0.6976 - lr: 5.0000e-05\n",
            "Epoch 46/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 2.0005 - accuracy: 0.6849\n",
            "Epoch 00046: val_loss improved from 1.43961 to 1.43034, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/046.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 2.0005 - accuracy: 0.6849 - val_loss: 1.4303 - val_accuracy: 0.6735 - lr: 5.0000e-05\n",
            "Epoch 47/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9831 - accuracy: 0.6954\n",
            "Epoch 00047: val_loss improved from 1.43034 to 1.42650, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/047.h5\n",
            "59/59 [==============================] - 117s 2s/step - loss: 1.9831 - accuracy: 0.6954 - val_loss: 1.4265 - val_accuracy: 0.6873 - lr: 5.0000e-05\n",
            "Epoch 48/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9918 - accuracy: 0.7012\n",
            "Epoch 00048: val_loss did not improve from 1.42650\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9918 - accuracy: 0.7012 - val_loss: 1.4443 - val_accuracy: 0.6838 - lr: 5.0000e-05\n",
            "Epoch 49/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9770 - accuracy: 0.7148\n",
            "Epoch 00049: val_loss did not improve from 1.42650\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9770 - accuracy: 0.7148 - val_loss: 1.4918 - val_accuracy: 0.6117 - lr: 5.0000e-05\n",
            "Epoch 50/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9760 - accuracy: 0.7012\n",
            "Epoch 00050: val_loss did not improve from 1.42650\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9760 - accuracy: 0.7012 - val_loss: 1.4683 - val_accuracy: 0.6323 - lr: 5.0000e-05\n",
            "Epoch 51/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9877 - accuracy: 0.7046\n",
            "Epoch 00051: val_loss did not improve from 1.42650\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9877 - accuracy: 0.7046 - val_loss: 1.4747 - val_accuracy: 0.6289 - lr: 5.0000e-05\n",
            "Epoch 52/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9642 - accuracy: 0.7121\n",
            "Epoch 00052: val_loss did not improve from 1.42650\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9642 - accuracy: 0.7121 - val_loss: 1.4474 - val_accuracy: 0.6735 - lr: 5.0000e-05\n",
            "Epoch 53/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9403 - accuracy: 0.7301\n",
            "Epoch 00053: val_loss improved from 1.42650 to 1.41579, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/053.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.9403 - accuracy: 0.7301 - val_loss: 1.4158 - val_accuracy: 0.6873 - lr: 5.0000e-05\n",
            "Epoch 54/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9386 - accuracy: 0.7362\n",
            "Epoch 00054: val_loss did not improve from 1.41579\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.9386 - accuracy: 0.7362 - val_loss: 1.4784 - val_accuracy: 0.6117 - lr: 5.0000e-05\n",
            "Epoch 55/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9437 - accuracy: 0.7152\n",
            "Epoch 00055: val_loss did not improve from 1.41579\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9437 - accuracy: 0.7152 - val_loss: 1.4718 - val_accuracy: 0.6392 - lr: 5.0000e-05\n",
            "Epoch 56/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9344 - accuracy: 0.7216\n",
            "Epoch 00056: val_loss did not improve from 1.41579\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9344 - accuracy: 0.7216 - val_loss: 1.4536 - val_accuracy: 0.6632 - lr: 5.0000e-05\n",
            "Epoch 57/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.9207 - accuracy: 0.7318\n",
            "Epoch 00057: val_loss did not improve from 1.41579\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.9207 - accuracy: 0.7318 - val_loss: 1.4791 - val_accuracy: 0.6117 - lr: 5.0000e-05\n",
            "Epoch 58/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8966 - accuracy: 0.7407\n",
            "Epoch 00058: val_loss did not improve from 1.41579\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8966 - accuracy: 0.7407 - val_loss: 1.4610 - val_accuracy: 0.6460 - lr: 5.0000e-05\n",
            "Epoch 59/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8946 - accuracy: 0.7393\n",
            "Epoch 00059: val_loss improved from 1.41579 to 1.40971, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/059.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8946 - accuracy: 0.7393 - val_loss: 1.4097 - val_accuracy: 0.7113 - lr: 5.0000e-05\n",
            "Epoch 60/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8640 - accuracy: 0.7488\n",
            "Epoch 00060: val_loss improved from 1.40971 to 1.37998, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/060.h5\n",
            "59/59 [==============================] - 118s 2s/step - loss: 1.8640 - accuracy: 0.7488 - val_loss: 1.3800 - val_accuracy: 0.7251 - lr: 5.0000e-05\n",
            "Epoch 61/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8834 - accuracy: 0.7407\n",
            "Epoch 00061: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.8834 - accuracy: 0.7407 - val_loss: 1.4105 - val_accuracy: 0.7010 - lr: 5.0000e-05\n",
            "Epoch 62/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8472 - accuracy: 0.7651\n",
            "Epoch 00062: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8472 - accuracy: 0.7651 - val_loss: 1.4885 - val_accuracy: 0.6048 - lr: 5.0000e-05\n",
            "Epoch 63/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8451 - accuracy: 0.7668\n",
            "Epoch 00063: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8451 - accuracy: 0.7668 - val_loss: 1.4791 - val_accuracy: 0.6220 - lr: 5.0000e-05\n",
            "Epoch 64/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8422 - accuracy: 0.7750\n",
            "Epoch 00064: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8422 - accuracy: 0.7750 - val_loss: 1.4680 - val_accuracy: 0.6460 - lr: 5.0000e-05\n",
            "Epoch 65/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8221 - accuracy: 0.7760\n",
            "Epoch 00065: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8221 - accuracy: 0.7760 - val_loss: 1.4666 - val_accuracy: 0.6564 - lr: 5.0000e-05\n",
            "Epoch 66/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8216 - accuracy: 0.7818\n",
            "Epoch 00066: val_loss did not improve from 1.37998\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.8216 - accuracy: 0.7818 - val_loss: 1.4202 - val_accuracy: 0.6907 - lr: 5.0000e-05\n",
            "Epoch 67/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8077 - accuracy: 0.7757\n",
            "Epoch 00067: val_loss improved from 1.37998 to 1.36985, saving model to drive/My Drive/1NOSYNC/DT/checkpoint/2021-12-9-7-7-32-personality/067.h5\n",
            "59/59 [==============================] - 119s 2s/step - loss: 1.8077 - accuracy: 0.7757 - val_loss: 1.3698 - val_accuracy: 0.7251 - lr: 5.0000e-05\n",
            "Epoch 68/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7929 - accuracy: 0.7882\n",
            "Epoch 00068: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7929 - accuracy: 0.7882 - val_loss: 1.3938 - val_accuracy: 0.6873 - lr: 5.0000e-05\n",
            "Epoch 69/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.8007 - accuracy: 0.7770\n",
            "Epoch 00069: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 116s 2s/step - loss: 1.8007 - accuracy: 0.7770 - val_loss: 1.4543 - val_accuracy: 0.6357 - lr: 5.0000e-05\n",
            "Epoch 70/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7967 - accuracy: 0.7808\n",
            "Epoch 00070: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7967 - accuracy: 0.7808 - val_loss: 1.4593 - val_accuracy: 0.6323 - lr: 5.0000e-05\n",
            "Epoch 71/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7789 - accuracy: 0.8059\n",
            "Epoch 00071: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7789 - accuracy: 0.8059 - val_loss: 1.5153 - val_accuracy: 0.6151 - lr: 5.0000e-05\n",
            "Epoch 72/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7538 - accuracy: 0.8012\n",
            "Epoch 00072: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7538 - accuracy: 0.8012 - val_loss: 1.4383 - val_accuracy: 0.6254 - lr: 5.0000e-05\n",
            "Epoch 73/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7463 - accuracy: 0.7995\n",
            "Epoch 00073: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7463 - accuracy: 0.7995 - val_loss: 1.4763 - val_accuracy: 0.6357 - lr: 5.0000e-05\n",
            "Epoch 74/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7358 - accuracy: 0.7950\n",
            "Epoch 00074: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7358 - accuracy: 0.7950 - val_loss: 1.4419 - val_accuracy: 0.6598 - lr: 5.0000e-05\n",
            "Epoch 75/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7174 - accuracy: 0.8103\n",
            "Epoch 00075: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7174 - accuracy: 0.8103 - val_loss: 1.4086 - val_accuracy: 0.6976 - lr: 5.0000e-05\n",
            "Epoch 76/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6924 - accuracy: 0.8334\n",
            "Epoch 00076: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.6924 - accuracy: 0.8334 - val_loss: 1.4222 - val_accuracy: 0.6804 - lr: 5.0000e-05\n",
            "Epoch 77/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.7164 - accuracy: 0.8188\n",
            "Epoch 00077: val_loss did not improve from 1.36985\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.7164 - accuracy: 0.8188 - val_loss: 1.4174 - val_accuracy: 0.6873 - lr: 5.0000e-05\n",
            "Epoch 78/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6906 - accuracy: 0.8287\n",
            "Epoch 00078: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.6906 - accuracy: 0.8287 - val_loss: 1.4015 - val_accuracy: 0.7045 - lr: 2.5000e-05\n",
            "Epoch 79/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6642 - accuracy: 0.8351\n",
            "Epoch 00079: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 114s 2s/step - loss: 1.6642 - accuracy: 0.8351 - val_loss: 1.4166 - val_accuracy: 0.6804 - lr: 2.5000e-05\n",
            "Epoch 80/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6262 - accuracy: 0.8566\n",
            "Epoch 00080: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 114s 2s/step - loss: 1.6262 - accuracy: 0.8566 - val_loss: 1.4417 - val_accuracy: 0.6564 - lr: 2.5000e-05\n",
            "Epoch 81/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.8464\n",
            "Epoch 00081: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.6272 - accuracy: 0.8464 - val_loss: 1.3989 - val_accuracy: 0.7045 - lr: 2.5000e-05\n",
            "Epoch 82/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6204 - accuracy: 0.8549\n",
            "Epoch 00082: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.6204 - accuracy: 0.8549 - val_loss: 1.5497 - val_accuracy: 0.6117 - lr: 2.5000e-05\n",
            "Epoch 83/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.6018 - accuracy: 0.8535\n",
            "Epoch 00083: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.6018 - accuracy: 0.8535 - val_loss: 1.4256 - val_accuracy: 0.6838 - lr: 2.5000e-05\n",
            "Epoch 84/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5824 - accuracy: 0.8603\n",
            "Epoch 00084: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.5824 - accuracy: 0.8603 - val_loss: 1.4022 - val_accuracy: 0.6942 - lr: 2.5000e-05\n",
            "Epoch 85/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5847 - accuracy: 0.8698\n",
            "Epoch 00085: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.5847 - accuracy: 0.8698 - val_loss: 1.5198 - val_accuracy: 0.6186 - lr: 2.5000e-05\n",
            "Epoch 86/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5674 - accuracy: 0.8702\n",
            "Epoch 00086: val_loss did not improve from 1.36985\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.5674 - accuracy: 0.8702 - val_loss: 1.4287 - val_accuracy: 0.6907 - lr: 2.5000e-05\n",
            "Epoch 87/1000\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.8787\n",
            "Epoch 00087: val_loss did not improve from 1.36985\n",
            "Restoring model weights from the end of the best epoch: 67.\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "59/59 [==============================] - 115s 2s/step - loss: 1.5483 - accuracy: 0.8787 - val_loss: 1.4774 - val_accuracy: 0.6529 - lr: 2.5000e-05\n",
            "Epoch 00087: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting...\n",
            "7/7 [==============================] - 18s 2s/step\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 78 145]\n",
            " [ 34  69]]\n",
            "\n",
            "Evaluating...\n",
            "7/7 [==============================] - 11s 1s/step - loss: 1.5611 - accuracy: 0.4509\n",
            "\n",
            "Per class accuracy:\n",
            "0: 0.34977578475336324\n",
            "1: 0.6699029126213593\n",
            "Average class accuracy: 0.5098393486873612\n",
            "F1 score: [0.46567164 0.43533123]. Avg F1: 0.4505014360374782\n"
          ]
        }
      ]
    }
  ]
}